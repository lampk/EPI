[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dịch tễ học",
    "section": "",
    "text": "This is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "epibasic_08_causal_inference.html",
    "href": "epibasic_08_causal_inference.html",
    "title": "8  Suy diễn nhân quả",
    "section": "",
    "text": "Cách tiếp cận cổ điển về suy diễn nhân quả được phát xuất từ cuộc tranh luận về mối quan hệ nhân quả giữa hút thuốc lá và ung thư phổi trong những năm thuộc thập niên 50-60.\n\n\nVào những năm 50-60, bối cảnh của cuộc tranh luận này như sau:\n\nKết quả từ các nghiên cứu dịch tễ học đã chỉ ra mối liên hệ của việc hút thuốc với việc tăng nguy cơ mắc bệnh ung thư phổi và các bệnh ung thư khác, bệnh tim mạch vành, bệnh “khí phế thủng” và “viêm phế quản”. Trong đó, những dữ liệu liên quan nhất đến từ các nghiên cứu đoàn hệ, bệnh chứng và các mô hình động vật và nghiên cứu trong phòng thí nghiệm mô tả các thành phần của khói thuốc lá.\nTỷ lệ tử vong do ung thư phổi và bệnh tim mạch vành ngày càng tăng đã tạo ra một yêu cầu cấp thiết phải hành động để giảm hút thuốc lá.\n\nTuy nhiên, để thực hiện hành động, chúng ta cần phải xác định được hút thuốc là nguyên nhân làm tăng tỷ lệ tử vong.\nNgành công nghiệp thuốc lá đã thực hiện một chiến lược trên quy mô lớn để đặt câu hỏi về độ tin cậy của bằng chứng dịch tễ học nói chung và của các nghiên cứu quan trọng nhất nói riêng. Chiến thuật tạo ra sự nghi ngờ về bằng chứng này đã làm gia tăng căng thẳng xung quanh thách thức diễn giải những phát hiện của nghiên cứu dịch tễ học. Điều này cho thấy tầm quan trọng về mặt xã hội của việc xác định nguyên nhân. Ngày nay, việc tạo ra và phổ biến sự hoài nghi vẫn là chiến lược được sử dụng rộng rãi bởi các bên liên quan có lợi ích tiềm ẩn bị đe dọa bởi phát hiện được nguyên nhân.\nCách tiếp cận để suy diễn nhân quả trong những năm 1960 dựa vào đánh giá của chuyên gia theo một bộ hướng dẫn hoặc tiêu chí (Bảng 1). Hút thuốc là một nguyên nhân mạnh mẽ của ung thư phổi: làm tăng nguy cơ ung thư phổi lên khoảng 20 lần và dẫn đến hầu hết các trường hợp ung thư phổi. Vì thế, bằng chứng từ các nghiên cứu quan sát rất nhất quán và mạnh mẽ, và chiều thời gian rõ ràng.\n\nNhững tiêu chí này (mà Hill gọi là “quan điểm cá nhân”) không phải là những tiêu chí tuyệt đối và không bắt buộc cần phải đáp ứng tất cả các tiêu chí để suy diễn nhân quả. Trên thực tế, chỉ có chiều thời gian là cần thiết. Một số tiêu chí, đáng chú ý nhất là tính đặc hiệu, đã được chứng minh là có ít khả năng áp dụng cho các bệnh không lây nhiễm có nhiều nguyên nhân.\nNhững hạn chế của cách tiếp cận cổ điển này bao gồm:\n\nDễ bị ảnh hưởng bởi tính chủ quan trong việc đánh giá bằng chứng\nDễ bị ảnh hưởng bởi sự thao túng bằng chứng\nCác bên liên quan có khả năng bị ảnh hưởng bởi phát hiện rằng mối liên hệ có hoặc không có quan hệ nhân quả có thể có quan điểm đối lập về việc giải thích bằng chứng.\nGiả định mối quan hệ trực tiếp đơn giản giữa nguyên nhân và kết quả giả định mà không xem xét rõ ràng cấu trúc của các quá trình nhân quả bên dưới. Suy luận về nguyên nhân trở thành cơ sở cho sự can thiệp, nhưng các kết luận về nguyên nhân không nằm trong hệ quả của các hành động cụ thể nhằm giảm hoặc loại bỏ nguyên nhân.\n\nVí dụ, hút thuốc lá là nguyên nhân không thể chối cãi của bệnh ung thư phổi, nhưng xa hơn trong quá trình nhân quả, một số ít các công ty thuốc lá đa quốc gia sản xuất hầu hết thuốc lá được bán và hút trên toàn thế giới (Hình 1). Cuối cùng, các can thiệp y tế công cộng chủ yếu nhắm vào cá nhân người hút thuốc, thay vì các yếu tố nguồn như hệ thống sản xuất, quảng cáo và phân phối thuốc lá.\nSự giới hạn về trọng tâm là một đặc điểm chính của cách tiếp cận truyền thống: các nhà dịch tễ học và những chuyên gia về y tế công cộng xác định vai trò nhân quả của các yếu tố nguy cơ khác nhau mà không xem xét đến tác động của một cách cụ thể để thay đổi chúng.\n\n\n\n\nNgày nay, thực hành y tế công cộng bị ảnh hưởng bởi cả cách tiếp cận cổ điển và hiện đại, như trong ví dụ sau đây.\nKhi thiết lập các tiêu chuẩn chất lượng không khí ngoài trời ở Mỹ, suy luận nhân quả và cả các yếu tố phản thực có liên quan đều được đưa ra trong quá trình ra quyết định.\nHai phần của Đạo luật Không khí Sạch (108 và 109) của Mỹ đề cập đến các chất gây ô nhiễm không khí ngoài trời chính, yêu cầu Quản trị viên của EPA đặt ra Tiêu chuẩn Chất lượng Quốc gia về Không khí Xung quanh (NAAQS) sao cho “việc đạt được và duy trì các tiêu chuẩn đó theo đánh giá của Quản trị viên, dựa trên các tiêu chí như vậy và cho phép một biên độ an toàn thích hợp, là cần thiết để bảo vệ sức khỏe cộng đồng” (p. 5697). Cụm từ “các tiêu chí như vậy” đề cập đến bằng chứng tích lũy về tác hại, nhấn mạnh đến điều được báo cáo kể từ lần xem xét NAAQS cuối cùng. Quy trình hiện tại đối với chất gây ô nhiễm, ví dụ như ôzôn, bắt đầu bằng việc xem xét bằng chứng, được tập hợp trong Đánh giá Khoa học Tích hợp (Hình 2). Quá trình suy luận nhân quả dựa trên cách tiếp cận cổ điển lâu đời và phân loại độ mạnh của bằng chứng theo sơ đồ năm cấp (“không có khả năng”, “không đầy đủ”, “gợi ý”, “có khả năng” và “quan hệ nhân quả”). Việc phân loại, một phần, xác định các tác động được xem xét sau đó trong phân tích rủi ro, ước tính gánh nặng bệnh tật liên quan đến chất ô nhiễm và hậu quả của những thay đổi tiềm ẩn đối với NAAQS. Những tác động mà bằng chứng đạt đến mức độ “có khả năng” hoặc “quan hệ nhân quả” thường được đưa ra để xem xét trong phân tích rủi ro và do đó được đưa ra trong phán đoán chính sách do Quản trị viên đưa ra về việc sửa đổi NAAQS cho chất gây ô nhiễm. Phân tích rủi ro mô hình phân phối phản thực của kết cuộc sức khỏe theo các kịch bản giảm ô nhiễm khác nhau và không can thiệp. Phân tích rủi ro dựa trên nền tảng là cách tiếp cận hiện đại.\n\nCơ quan Nghiên cứu Ung thư Quốc tế (IARC) của Tổ chức Y tế Thế giới vận hành Chương trình Chuyên khảo, tiến hành các đánh giá có hệ thống để phân loại các tác nhân theo khả năng gây ung thư của chúng. Cách tiếp cận chung bao gồm một cuộc họp của một nhóm làm việc đa ngành để xem xét bằng chứng liên quan đến một tác nhân cụ thể trong bốn loại chính: (a) phơi nhiễm, (b) nghiên cứu về ung thư ở người, (c) nghiên cứu về ung thư ở động vật thí nghiệm và ( d) dữ liệu về cơ chế và các dữ liệu liên quan khác. Bằng chứng trên người và động vật được xem xét riêng biệt và đối với mỗi loại, độ mạnh của bằng chứng về nguyên nhân được phân loại theo lược đồ phân cấp bốn cấp độ: đủ, hạn chế, không đầy đủ hoặc gợi ý thiếu khả năng gây ung thư. Bằng chứng được đánh giá bằng cách tiếp cận dựa trên tiêu chí Hill hoặc cổ điển. Bằng chứng về vai trò của các cơ chế cụ thể được đánh giá là “yếu”, “trung bình” hoặc “mạnh” và các nhà nghiên cứu xem xét sự liên quan của cơ chế đối với bệnh ung thư ở người. Việc phân loại tổng thể chủ yếu dựa trên các phát hiện trên động vật và con người (Hình 3), nhưng bằng chứng cơ học cũng có thể được sử dụng trong quá trình phân loại. Ví dụ, cách tiếp cận này đã dẫn đến việc phân loại bức xạ điện từ tần số vô tuyến năm 2011, loại phát ra từ điện thoại di động, là chất có thể gây ung thư ở người, Nhóm 2B trong lược đồ IARC."
  },
  {
    "objectID": "epibasic_08_causal_inference.html#cách-tiếp-cận-hiện-đại",
    "href": "epibasic_08_causal_inference.html#cách-tiếp-cận-hiện-đại",
    "title": "8  Suy diễn nhân quả",
    "section": "8.2 Cách tiếp cận hiện đại",
    "text": "8.2 Cách tiếp cận hiện đại\nVai trò chính của suy diễn nhân quả trong y tế công cộng là so sánh sự phân bố của kết cuộc sức khỏe sau khi thực hiện các biện pháp can thiệp khác nhau. Trong một thế giới lý tưởng, những so sánh này sẽ được thực hiện thông qua các thực nghiệm phân nhóm ngẫu nhiên và tất cả các quyết định về y tế công cộng đồng nên dựa trên kết quả của những thực nghiệm đó. Ví dụ, việc tích hợp các chương trình cai thuốc lá vào hệ thống chăm sóc sức khỏe sẽ là lý tưởng nếu dựa trên những phát hiện từ các nghiên cứu phân nhóm ngẫu nhiên dài hạn nhằm so sánh hiệu quả của can thiệp ở các nhóm lớn người từ dân số mục tiêu tuân thủ can thiệp với các nhóm kiểm soát. Tương tự, quyết định tăng thuế hoặc quy định đối với các sản phẩm thuốc lá sẽ dựa trên các nghiên cứu phân bổ ngẫu nhiên các chính sách này giữa các cộng đồng hoặc quận. Thật không may, những thử nghiệm ngẫu nhiên như vậy thường phi đạo đức, không thực tế hoặc đơn giản là quá lâu để đưa ra quyết định kịp thời. Do đó, các suy diễn nhân quả đối với y tế công cộng thường bắt nguồn từ các nghiên cứu quan sát, được củng cố bởi các loại bằng chứng khác nếu có.\nViệc sử dụng dữ liệu quan sát, thay vì thử nghiệm, để suy luận nhân quả trong sức khỏe cộng đồng gây ra một số lo ngại. Một mối quan tâm đặc biệt liên quan đến sức khỏe cộng đồng là các biện pháp can thiệp đang được xem xét có thể được xác định một cách mơ hồ, từ đó hạn chế mức độ liên quan của các phát hiện đối với việc ra quyết định về sức khỏe cộng đồng. Ví dụ: so sánh tỷ lệ tử vong quan sát được giữa người béo phì và người gầy cho thấy mối quan hệ nhân quả có thể có giữa béo phì và tử vong nhưng đưa ra rất ít hướng dẫn cho hành động: nên tìm giải pháp trong các chương trình tập thể dục tại nơi làm việc, giảm kích cỡ nước ngọt có đường bán lẻ cửa hàng, hay hút mỡ? Mặc dù béo phì có thể đáp ứng các tiêu chí về yếu tố nguyên nhân trong cách tiếp cận cổ điển, nhưng mối liên hệ giữa béo phì và tỷ lệ tử vong mang lại rất ít hiểu biết cho hành động phòng ngừa. Một giải pháp thay thế là tập trung vào sự tương phản giữa các cá nhân được chỉ định ngẫu nhiên để điều chỉnh chế độ ăn uống so với những người không hoặc sự tương phản giữa các cộng đồng được chọn ngẫu nhiên để đánh thuế đồ uống có đường so với những người không. Những phát hiện từ những thử nghiệm như vậy sẽ cung cấp thông tin trực tiếp, có thể hành động về tác động của các biện pháp can thiệp chống béo phì. Nghiên cứu quan sát so sánh người béo phì và người gầy chỉ cung cấp bằng chứng gián tiếp và thiếu mối quan hệ nhân quả có thể kiểm chứng chính thức nếu không có thêm mô tả chi tiết.\nMột cách để giải quyết mối lo ngại này và thu hẹp khoảng cách giữa dữ liệu quan sát và quá trình ra quyết định về sức khỏe cộng đồng là thiết kế các phân tích quan sát theo cách sao cho dữ liệu quan sát mô phỏng dữ liệu từ các thử nghiệm ngẫu nhiên giả định với các biện pháp can thiệp tương đối rõ ràng. Ví dụ, dữ liệu quan sát có thể được sử dụng để bắt chước một thử nghiệm ngẫu nhiên giả định liên quan đến các can thiệp chế độ ăn uống bằng cách so sánh kết quả quan sát được của những cá nhân thay đổi so với những người không thay đổi chế độ ăn uống của họ trong suốt thời gian nghiên cứu; hoặc dữ liệu có thể được sử dụng để bắt chước một thử nghiệm ngẫu nhiên giả định về chính sách thực phẩm bằng cách so sánh kết quả sức khỏe giữa các trường đã hạn chế và không hạn chế tiếp cận đồ uống có đường. Cách tiếp cận này được xây dựng trong cách tiếp cận kết cuộc phản thực tế hoặc tiềm năng do Neyman đề xuất, được mở rộng bởi Rubin và được Robins tổng quát hóa cho các mức độ phơi nhiễm thay đổi theo thời gian. Một cách tiếp cận phản thực đối với suy diễn nhân quả trong y tế công cộng đòi hỏi các tác động nhân quả được xác định theo sự tương phản giữa sự phân bổ các kết cuộc sức khỏe theo các can thiệp được xác định rõ (giả thuyết) khác nhau.\nTuy nhiên, việc so sánh các biện pháp can thiệp y tế công cộng tương đối rõ ràng chỉ là vấn đề đầu tiên đối với suy luận nhân quả từ dữ liệu quan sát. Ngay cả các nhóm can thiệp được xác định rõ ràng thường sẽ không thể so sánh trực tiếp được vì các đặc điểm chính của các cá nhân trong mỗi nhóm có thể khác nhau. Ví dụ, những cá nhân thay đổi chế độ ăn uống của họ cũng có thể áp dụng lối sống lành mạnh hơn những người không thay đổi, và những trường học thay đổi chính sách thực phẩm của họ có thể phục vụ những nhóm dân cư ít bất bình đẳng kinh tế hơn so với những trường học không thay đổi chính sách. Vấn đề không thể so sánh này, thường được gọi là gây nhiễu, là một vấn đề cơ bản đối với suy diễn nhân quả sử dụng dữ liệu quan sát.\nCách tiếp cận phổ biến nhất để giảm thiểu nhiễu là đo lường càng nhiều biến số chịu trách nhiệm về tính không thể so sánh càng tốt và điều chỉnh chúng trong phân tích thống kê. Các phương pháp có sẵn để điều chỉnh các yếu tố gây nhiễu đo được là phân tầng, đối sánh, tiêu chuẩn hóa, trọng số xác suất nghịch đảo và ước tính-g. Trong các ứng dụng thực tế với dữ liệu thưa thớt hoặc nhiều chiều, các phương pháp điều chỉnh này được thực hiện với sự trợ giúp của các mô hình thống kê. Ví dụ, điều chỉnh thông qua phân tầng thường được thực hiện bằng cách sử dụng các mô hình hồi quy thông thường.\nĐôi khi các yếu tố gây nhiễu đo được được sử dụng để ước tính xác suất nhận được phơi nhiễm quan tâm của mỗi người tham gia nghiên cứu. Đối với các biến số phơi nhiễm dạng nhị giá (ví dụ: có/không), xác suất này được gọi là điểm khuynh hướng (propensity score). Nếu có điểm khuynh hướng để điều chỉnh, thì không cần đến các biến số riêng lẻ nữa. Trọng số nghịch đảo xác suất và ước tính g là các phương pháp dựa trên điểm xu hướng. Điểm xu hướng cũng có thể được sử dụng để hiệu chỉnh sự gây nhiễu thông qua phân tầng (ví dụ: bằng cách thêm điểm xu hướng dưới dạng đồng biến số trong mô hình hồi quy), bắt cặp và chuẩn hóa.\nĐể các phương pháp trên cung cấp kết luận hợp lệ về nhân quả, tất cả các yếu tố gây nhiễu phải được xác định và đo lường một cách thích hợp, và đây là một điều kiện không thể kiểm chứng bằng thực nghiệm. Một phương pháp khác để loại bỏ nhiễu khỏi ước tính tác động là ước lượng dựa vào biến công cụ (instrument variable). Không giống như các phương pháp khác, ước lượng dựa trên biến công cụ không yêu cầu các nhà điều tra đo lường bất kỳ yếu tố gây nhiễu nào. Thay vào đó, phương pháp này yêu cầu họ xác định và đo lường một cách thích hợp một biến số công cụ, được định nghĩa đại khái là một biến số có ảnh hưởng đến mức độ phơi nhiễm và không liên quan đến kết quả ngoại trừ thông qua tác động của nó đối với mức độ phơi nhiễm. Thật không may, không thể xác minh bằng thực nghiệm rằng một biến cụ thể là một biến số công cụ thích hợp. Hơn nữa, các biến số công cụ hợp lệ chỉ có thể cung cấp các giới hạn dưới và trên cho mức độ của tác động nhân quả quan tâm. Thông thường, những giới hạn này không hữu ích cho việc ra quyết định vì chúng bao gồm các tác động từ có lợi đến có hại. Kết quả là, hầu hết các ứng dụng của các biến số công cụ đều đưa ra các giả định bổ sung không thể kiểm chứng để có được các ước lượng điểm cho tác động quan tâm.\nKhi mức độ phơi nhiễm thay đổi theo thời gian, một vấn đề tiềm ẩn mới sẽ nảy sinh: Có lẽ bản thân các yếu tố gây nhiễu (cũng thay đổi theo thời gian) bị ảnh hưởng bởi các mức độ phơi nhiễm trước đó. Khi có quy trình phản hồi về yếu tố gây nhiễu - phơi nhiễm này, một số phương pháp trên—phân tầng và bắt cặp—nhìn chung là không thể được sử dụng để đưa ra suy diễn nhân quả hợp lệ. Điều chỉnh hợp lệ cho nhiễu đo được cần sử dụng đến công thức g tham số (tổng quát hóa tiêu chuẩn hóa) , nghịch đảo xác suất của các mô hình cấu trúc cận biên hoặc ước tính g của các mô hình cấu trúc lồng nhau (bao gồm một số các hình thức ước tính biến công cụ cho các mức độ phơi nhiễm thay đổi theo thời gian như một trường hợp cụ thể). Các phương pháp này do Robins và cộng sự phát triển từ năm 1986, thường được gọi là phương pháp nhân quả vì chúng có thể được áp dụng để thu được các suy luận nhân quả hợp lệ, ngay cả trong các bối cảnh phức tạp với các yếu tố gây nhiễu thay đổi theo thời gian bị ảnh hưởng bởi sự phơi nhiễm trước đó.\nMột bổ sung gần đây khác cho phương pháp suy luận nhân quả là việc sử dụng sơ đồ nhân quả (đồ thị không tuần hoàn có hướng hoặc DAG). Mặc dù bản thân nó không phải là một phương pháp phân tích dữ liệu, nhưng sơ đồ nhân quả được sử dụng để biểu thị cấu trúc của các mạng lưới nhân quả liên kết mức độ phơi nhiễm, kết cuộc, yếu tố gây nhiễu và các biến số khác, đòi hỏi phải xây dựng rõ ràng mối quan hệ giữa các yếu tố này. Do đó, sơ đồ nhân quả là một công cụ hữu ích để phát hiện, bằng đồ thị, các nguồn sai lệch có thể có và để hướng dẫn các nhà điều tra thiết kế phân tích dữ liệu của họ.\n\n8.2.1 Những thách thức để triển khai cách tiếp cận kết cuộc tiềm năng\nMặc dù cách tiếp cận kết cuộc tiềm năng là mạnh mẽ trong bối cảnh có nhiều câu hỏi về nguyên nhân có giá trị cao đối với sức khỏe cộng đồng, nhưng việc sử dụng nó đặt ra một số câu hỏi. Ví dụ: chúng ta có nên xem xét các câu hỏi nhân quả về các đặc điểm vốn có của cá nhân (chẳng hạn như giới tính, chủng tộc/sắc tộc hoặc tuổi tác) mà không thể diễn giải một cách hợp lý thành các can thiệp giả định? Và làm thế nào các nhà nghiên cứu nên giải quyết các yếu tố cá nhân (ví dụ: trọng lượng cơ thể) hoặc xã hội (ví dụ: mức thu nhập khu vực lân cận) có thể được chuyển thành các biện pháp can thiệp giả định nhưng lại tồn tại nhiều biện pháp can thiệp khả thi? Cách tiếp cận kết cuộc tiềm ẩn nhấn mạnh rằng khi chúng ta ước tính mối liên hệ giữa kết quả sức khỏe với các yếu tố không thể thay đổi, câu hỏi làm thế nào để thay đổi kết quả do các yếu tố đó gây ra vẫn còn bỏ ngỏ. Do đó, các nghiên cứu về mối liên hệ giữa các yếu tố không thể thay đổi và kết cuộc sức khỏe có thể được coi là khúc dạo đầu cho các nghiên cứu khác về các can thiệp giả định. Ví dụ: nếu các nghiên cứu quan sát cho chúng ta biết rằng những người sống ở các khu dân cư nghèo có tỷ lệ mắc bệnh ung thư cao hơn so với những người sống ở các khu dân cư giàu có hơn, thì chuỗi điều tra tiếp theo có thể xem xét các chế độ ăn uống hoặc phơi nhiễm chất gây ung thư có thể thay đổi được khác nhau giữa các cộng đồng đang được nghiên cứu. Phát hiện ban đầu về tỷ lệ ung thư cao hơn ở các cộng đồng nghèo là rất quan trọng trong việc thúc đẩy các nghiên cứu tìm ra nguyên nhân có thể được điều chỉnh. Nếu không có nghiên cứu sâu hơn như vậy, dịch tễ học sẽ chủ yếu trở thành một công cụ mô tả cho phân tích xã hội học và ít là một công cụ cung cấp bằng chứng dẫn đến các can thiệp để cải thiện sức khỏe.\nKhung kết cuộc tiềm năng cũng có thể được kết hợp với khung đa cấp độ để đưa bối cảnh trở lại dịch tễ học và sức khỏe cộng đồng (5, 6, 12, 48, 59). Vai trò nguyên nhân của các yếu tố bối cảnh cấp cao hơn có thể được đánh giá miễn là chúng có thể được định nghĩa là so sánh giữa các can thiệp hoặc chính sách khác nhau. Tuy nhiên, ngay cả khi có thể tưởng tượng được các can thiệp giả định đối với các chính sách quốc gia hoặc khu vực (mặc dù thường không thể thực hiện được), thì nhiều trong số các sự phơi nhiễm theo bối cảnh này là đồng nhất trong một xã hội, điều này gây khó khăn cho việc thu thập dữ liệu cần thiết để tiến hành đánh giá. Kết quả là, trong thực tế, các nhà dịch tễ học và các nhà thực hành y tế công cộng có thể được khuyến khích ưu tiên nghiên cứu các can thiệp gần và hạ nguồn ở cấp độ cá nhân. Ví dụ, sẽ dễ dàng hơn khi tiến hành hoặc mô phỏng bằng cách sử dụng dữ liệu quan sát, các thử nghiệm ngẫu nhiên về các chương trình cai thuốc nhắm vào cá nhân so với tiến hành các thử nghiệm về hành vi của các tổ chức doanh nghiệp được tài trợ tốt với các lợi ích được đầu tư và các mối quan hệ chính trị.\nKhung kết cuộc tiềm năng đã được mở rộng theo nhiều hướng để phù hợp với các quá trình nhân quả đa cấp độ. Các phương pháp tiếp cận mô hình chính thức đã phát sinh trong bệnh truyền nhiễm để xử lý nội sinh và can thiệp. Các phương pháp tiếp cận hệ thống phức tạp đã bắt đầu đưa ra các khuôn khổ mới cho các quá trình nhân quả trên nhiều quy mô địa lý và thời gian. Chúng đề xuất lập bản đồ các tác nhân và quy trình liên quan đến việc tạo ra kết quả và do đó, rất hữu ích để định hình nhiều thách thức cấp bách nhất về sức khỏe cộng đồng do các quy trình ở các cấp độ từ địa phương đến toàn cầu. Chúng cần được đưa ra để giải quyết các vấn đề sức khỏe cộng đồng khi thích hợp. Chúng chỉ ra dữ liệu nên được thu thập, cách tổ chức dữ liệu và cách dữ liệu nên được phân tích trong khung kết quả tiềm năng. Các phương pháp tiếp cận hệ thống phức hợp cũng có thể cung cấp những hiểu biết sâu sắc về hệ quả của các kết quả được thực hiện bởi các chủ thể khác nhau và ở các cấp độ khác nhau."
  },
  {
    "objectID": "epibasic_08_causal_inference.html#tương-lai-của-suy-diễn-nhân-quả-trong-y-tế-công-cộng",
    "href": "epibasic_08_causal_inference.html#tương-lai-của-suy-diễn-nhân-quả-trong-y-tế-công-cộng",
    "title": "8  Suy diễn nhân quả",
    "section": "8.3 Tương lai của suy diễn nhân quả trong y tế công cộng",
    "text": "8.3 Tương lai của suy diễn nhân quả trong y tế công cộng\nCác phương pháp suy luận nguyên nhân hiện tại có liên quan và hữu ích vì chúng không hướng đến việc xác định nguyên nhân mà nhằm xác định tác động của các biện pháp can thiệp. Các tiêu chí cổ điển cho suy luận nhân quả không tách biệt rõ ràng hai mục tiêu này, dẫn đến các cuộc tranh luận về việc quy kết nguyên nhân, trên thực tế, ngầm hiểu là về can thiệp thích hợp. Ngay cả khi chúng ta hiểu hoàn hảo về chuỗi nhân quả, tức là biết mọi yếu tố có thể được coi là nguyên nhân, chúng ta vẫn có thể không biết cách tốt nhất để thay đổi kết quả. Các phương pháp suy luận nhân quả mới hơn đưa chúng ta ra khỏi bài tập triết học về xác định nguyên nhân và buộc chúng ta phải xem xét sâu sắc hơn cách cải thiện sức khỏe thông qua các biện pháp can thiệp cụ thể.\nQuay trở lại ví dụ về thuốc lá, vì mục đích sức khỏe cộng đồng, việc ước tính tác động của việc giảm hút thuốc ở từng cá nhân nhất định ít quan trọng hơn so với ước tính hậu quả đối với sức khỏe của các chương trình cai thuốc lá so với thuế thuốc lá. Bài tập sau cung cấp một hướng dẫn để hành động. Nhưng điều khác biệt về hai biện pháp can thiệp này, ngoài tác động ước tính của chúng, là cách chúng ta đánh giá chúng. Hiệu quả của việc cai thuốc lá có thể được đánh giá bằng thử nghiệm ngẫu nhiên, nhưng việc mô tả các hậu quả của việc tăng thuế và các hình thức can thiệp xã hội khác có thể không được. Trong những tình huống như vậy, chúng ta phải sử dụng dữ liệu quan sát để mô phỏng thử nghiệm không thể tiến hành được. Càng rời xa thử nghiệm ngẫu nhiên để đánh giá, thì sự phụ thuộc vào mô hình hóa và kiến thức về chủ đề, bao gồm xã hội học và các lý thuyết khác càng lớn. Nhu cầu chuyển sang dữ liệu quan sát này đặt ra một vấn đề nan giải tiềm ẩn đối với sức khỏe cộng đồng; nếu chúng ta không thể tập trung vào các biện pháp can thiệp dễ đánh giá, chúng ta có thể bỏ qua các biện pháp can thiệp ngược dòng mà thử nghiệm ngẫu nhiên không thể được tiến hành hoặc mô phỏng nhưng có thể có tiềm năng tác động thay đổi lớn nhất. Các khuôn khổ và phương pháp suy luận nguyên nhân giúp chúng ta xác định các lựa chọn can thiệp và xác định cách tốt nhất để đánh giá tác động của chúng, nhưng chúng không nhất thiết cung cấp thông tin về các mức độ can thiệp liên quan cần xem xét và những biện pháp can thiệp nào nên được thực hiện.\nPhần thảo luận trước cho chúng ta thấy rằng những người nỗ lực cải thiện sức khỏe cộng đồng không thể bỏ qua các phương pháp suy luận nhân quả. Việc tập trung vào tác động của các biện pháp can thiệp hơn là nguyên nhân khiến khoa học về sức khỏe cộng đồng liên kết chặt chẽ hơn với thực tiễn của nó. Các phương pháp suy luận nhân quả mới buộc chúng ta phải đối mặt, như các phương pháp trước đây đã không làm, các biện pháp can thiệp sẽ ảnh hưởng đến sức khỏe cộng đồng như thế nào. Tuy nhiên, một số bước phải được thực hiện để chuyển các phương pháp này từ học viện sang thực tiễn. Đầu tiên, việc giảng dạy về sức khỏe cộng đồng, đặc biệt là trong các chương trình MPH (thạc sĩ về sức khỏe cộng đồng), thường nhấn mạnh vào khuôn khổ cổ điển. Trọng tâm hạn chế này cần phải được thay đổi để chúng ta có thể tạo ra một nhóm chuyên gia y tế công cộng mới, những người hiểu rõ hơn về nguyên nhân và sự liên quan của khung kết quả tiềm năng đối với công việc của họ. Thứ hai, các ví dụ nổi bật, dễ tiếp cận về tiện ích của khuôn khổ hiện đại cần được phát triển và phổ biến thông qua xuất bản và thuyết trình tại các cuộc họp chuyên môn mà các chuyên gia y tế công cộng tham dự. Ví dụ, một nghiên cứu trường hợp rất hữu ích có thể được phát triển xung quanh chiến lược đa thành phần được sử dụng để giải quyết vấn đề hút thuốc lá ở Thành phố New York (10). Trong giai đoạn 2002–2003, hút thuốc lá giảm mạnh ở Thành phố New York sau khi thực hiện chiến lược tích cực với các thành phần bao gồm tăng thuế, cấm hút thuốc trong nhà ở hầu hết các nơi làm việc, tăng dịch vụ cai nghiện và giáo dục. Những phương pháp này có thể được sử dụng để giải quyết tác động sức khỏe cộng đồng của lệnh cấm bán đồ uống chứa đường cỡ lớn có hiệu lực từ năm 2013. Sự can thiệp được công bố rộng rãi này mang lại một trường hợp thử nghiệm có giá trị.\nKhung kết quả tiềm năng nên được áp dụng khi thích hợp để đánh giá hiệu quả tiềm năng của các hành động y tế công cộng. Chúng tôi đã đề cập đến các công cụ phân tích mới được phát triển để làm sắc nét các phân tích dữ liệu quan sát trong khuôn khổ này, nhận ra rằng không thể thực hiện các thử nghiệm ngẫu nhiên thực sự đối với nhiều vấn đề. Các cách tiếp cận khác nắm bắt được sự phức tạp của các quy trình nhân quả với đủ hình thức để hữu ích như một khuôn khổ cho việc thu thập và phân tích dữ liệu và để xác định các mục tiêu can thiệp. Khi dữ liệu y tế công cộng được thu thập, chúng cần phải có đủ độ phong phú cho mục đích này. Các chuyên gia y tế công cộng không cần phải ngại suy luận nhân quả khi sử dụng các phương pháp mới hơn này vì sự phức tạp được nhận thức.\nKhi nguồn gốc của các câu hỏi mà các chuyên gia y tế công cộng phải đối mặt trở nên phức tạp và mang tính toàn cầu hơn, chúng ta ngày càng gặp nhiều thách thức trong việc hiểu thế giới một cách đầy đủ và nắm bắt được sự phức tạp của thế giới trong các mô hình và biện pháp can thiệp của mình để xác định các lĩnh vực cần thay đổi. Từ béo phì đến biến đổi khí hậu, làm thế nào chúng ta nên đo lường tác động của các nguyên nhân và nơi đầu tư được định hướng tốt nhất trở thành những câu hỏi với những hậu quả to lớn về sức khỏe và xã hội. Với rất nhiều nguy cơ và với số lượng thông tin được liên kết từ nhiều cấp độ—từ gen đến môi trường—mà các thế hệ trước chưa từng có, các công cụ khái niệm và định lượng của chúng tôi phải bắt kịp. Tiện ích của các phương pháp tiếp cận quen thuộc, đã được sử dụng từ lâu để phân tích thống kê và suy luận nguyên nhân nhằm diễn giải hàng loạt bằng chứng về các yếu tố quyết định nguyên nhân của sức khỏe con người đang giảm dần. Các nhà thực hành và nghiên cứu y tế công cộng phải hiểu những hạn chế của những phương pháp đó và cam kết tìm hiểu những phương pháp mới mang lại nếu chúng trở thành những hướng dẫn khoa học đáng tin cậy cho sức khỏe của các thế hệ tương lai."
  },
  {
    "objectID": "epibasic_08_causal_inference.html#tham-khảo",
    "href": "epibasic_08_causal_inference.html#tham-khảo",
    "title": "8  Suy diễn nhân quả",
    "section": "8.4 Tham khảo",
    "text": "8.4 Tham khảo\n(Westreich 2020)\n\nWestreich, Daniel. 2020. Epidemiology by Design: A Causal Approach to the Health Sciences. New York, NY: Oxford University Press.\nThere is a rich and growing literature on causal inference and causal effect estimation (Greenland, 2017; Hernán & Robins, 2019). Here, our goal is a brief introduction to concepts, terms, and notation. Many concepts introduced here will be developed further in subsequent chapters. For example, we introduce the idea of confounding in this chapter, but expand on that concept in discussing randomized trials (in Chapter 5) and observational cohort studies (Chapter 6).\nIn this chapter, we discuss elements of causal inference, causal effect estimation, systematic error, and related concepts. Along the way, we will discuss the circumstances under which we can interpret the measures of association discussed in the previous chapter and estimates of those measures, as measures and estimates of causal effects. As noted in the Acknowledgements, this Chapter in particular owes a particular debt of intellectual influence to numerous key scientists cited below. Hopefully, the citations throughout the Chapter reflect this debt; if not, however, I want to be clear that in this Chapter more than others I am standing on the shoulders of numerous others.\n\n8.4.1 EPIDEMIOLOGIC PARADIGMS: DESCRIPTIVE, PREDICTIVE, CAUSAL\nEpidemiology is the core science of public health, and public health is the field\ndedicated to intervening to improve health at the population level. Of course, we\nonly want to intervene on factors which are causal: to intervene on noncausal\nexposures will not change health (or, at least, not in the way we think). For example: drinking alcohol can increase risk of car accidents, while drinking coffee\ngenerally does not. But if it was true that people who drink alcohol are more likely\nthan others to drink coffee, we might observe an association between drinking\ncoffee and increased risk of car accidents—an association actually due to the association of alcohol with both coffee consumption and risk of car accidents. An\nobserved association between coffee consumption and risk of car accidents may\nhelp us predict who is likely to be in a car accident (coffee drinkers); but, in this\ncase, using that information as a reason to persuade people to stop drinking coffee\n(i.e., to intervene on coffee consumption) in an effort to prevent car accidents is\nclearly misguided because there is no causal effect of coffee on accident risk.\nA chief concern of epidemiology, therefore, is estimating causal effects: understanding the impact of exposure to some factor or treatment on health outcomes.\nHowever, there are two other epidemiologic paradigms which we will address in\nthis book: descriptive and predictive epidemiology. Both of these are addressed\nin more depth in Chapter 4, but we discuss them briefly here because doing so\nhelps delineate what is meant by causal epidemiology. Descriptive epidemiology\nis concerned with communicating the observed world as it is—for example, in\ncharacterizing the prevalence of some disease in the population. Whereas predictive epidemiology is concerned with diagnostic testing (given your characteristics\nor test results, are you likely to have a particular disease which is not directly observable?) and prognostics (given your characteristics, are you likely to acquire\na particular disease? Given your characteristics and your disease, how will your\nhealth evolve in the next months or years?). The borders of these paradigms are\nfuzzy, of course: diagnostic testing can be seen as a form of description of the world.\nThe borders of these paradigms are fuzzy, of course: for example, diagnostic\ntesting can be seen as a form of description of the world. Both descriptive and\npredictive epidemiology are important to public health: descriptive epidemiology,\noften in the form of disease surveillance efforts (Chapter 4), tells us how prevalent\na particular disease might be and thus helps us prioritize resources. Predictive epidemiology may help patients understand whether they have a disease or how their\ndisease may progress over time (arguably the domain of clinical epidemiology),\nbut it may also help inform prevention efforts by forecasting future disease burden.\nAgain, we go into more depth on both these paradigms in the next chapter: here,\nwe concern ourselves chiefly with identification and estimation of causal effects.\n\n\n8.4.2 COUNTERFACTUAL THINKING AND POTENTIAL OUTCOMES\nConsider Jimmy, who is driving his car on the freeway. Jimmy gets a text message, so he picks up his phone to read it and he nearly immediately gets into an\naccident. We might reasonably ask, “Did reading the text message cause Jimmy’s\naccident?” But what is it that we mean—really mean—when we ask this question?\nWhat we mean is often something like the following: “What if Jimmy had not\nread the text message: would he, nonetheless, still have gotten into the accident?”\nWhen we ask that question, we just as often have in our heads this set of responses:\nIf Jimmy would still have gotten into the accident even if he had not read the\ntext message, then reading the text message did not cause his accident.\nBut if Jimmy would not have gotten into the accident had he not read the\ntext message, then reading that text message did cause his accident.\nThat what-if question, a kind of experiment we run in our own head, captures\nthe essence of a counterfactual approach to causality. We compare what factually happened (Jimmy read the text and got into a car accident) with what would have happened if, counter to fact, had Jimmy not read the text. This approach—\nsometimes called “but-for” (or sine qua non) causality in the law—is closely related to potential outcomes, words which are often used synonymously with\ncounterfactuals.\nTo help us think clearly through these ideas, we introduce some simple notation. We consider a two-category exposure X, for example “current smoking”\ncompared with “no current smoking.” Alternatively, we can think of X as a treatment chosen by a patient or assigned in a randomized trial, such as “assigned to\nreceive an influenza immunization” compared with “assigned to receive a placebo\ninjection.” In general we will consider X = 1 to indicate the “exposed” or “treated”\ncategory (e.g., exposed to current smoking or assignment to immunization) and\nX = 0 to indicate “unexposed” or “untreated.”\nWe consider also a two-category outcome Y, such as “had a heart attack\nwithin 1 year” compared with “did not have a heart attack within 1 year” or “was\nhospitalized within 30 days” compared with “was not hospitalized within 30 days”\nor “died within 10 years” compared with “alive at the end of 10 years.” In general we will consider Y = 1 to indicate “had a poor health outcome” (e.g., had a\nheart attack within 1 year) and Y = 0 to indicate “did not have a poor health outcome” (e.g., did not have a heart attack within 1 year). Both X and Y are specific\nto individuals, so both may be subscripted with i to indicate which individual is\nbeing considered: i can range from 1 to n or 1 to N, where n (N) is often used to\nindicate the number of individuals in the study (population).\nAs in previous chapters, we make several simplifying assumptions about risks\nand related measures. In particular, we assume that the time period over which\nstudy participants were followed is fixed and follow-up is complete (no one\ndisappears, such that we do not record their outcome status). We also assume no\ncompeting risks, that no other events occurred which prevent the outcome of interest from occurring: for example, we assume that hospitalization within 30 days\nwas not prevented by a study participant’s death. In some cases we will leave the\ntime period in which the outcome must have occurred implicit, although it is\ngenerally necessary to state it (see Chapters 1 and 2). Such assumptions are not\nnecessary and can be relaxed under some circumstances.\n\n8.4.2.1 An Example\nNow consider an experiment in which we flip a coin to determine the treatment\n(say, an active drug or a placebo) to which an individual is assigned. In particular,\nsuppose we wish to randomize individuals who have just suffered a first heart attack to receive either a single dose of a new, long-acting drug or a single dose of a\nplacebo; we will then follow all individuals for a year to assess the risk of death in\neach treatment group. Consider one participant in this randomized trial, Sarah,\nwho adheres to the treatment to which she is assigned in the trial.\nBefore we flip the coin to assign Sarah to one arm of the trial or another, Sarah\nhas two potential outcomes. There is her potential outcome under assignment to\nexposure X = 1: the outcome Sarah would experience if the coin comes up heads and she is assigned to receive the active drug. And there is her potential outcome\nunder assignment to exposure X = 0: the outcome Sarah would experience if the\ncoin comes up tails and she is assigned to receive the placebo.1 We designate these\npotential outcomes Yx = 1 and Yx = 0, respectively. Both of these potential outcomes\nare mathematical abstractions; we may get to observe the value of one of these\npotential outcomes in reality, but not more than one. Potential outcomes were\nfirst described by Neyman in 1923 (1923/1990) and then popularized by Rubin in\n1974 and thereafter.\nSarah has two potential outcomes—and each potential outcome has two possible\nvalues: at the end of the year of follow-up, she might be alive or dead. Specifically,\nif she is assigned the active drug, then, by the end of the year, she may have died\n(Yx = 1 = 1) or not died (Yx = 1 = 0); likewise, if she is assigned the placebo, by the\nend of the year she may have died (Yx = 0 = 1) or not died (Yx = 0 = 0). Note that in\nthe case of an exposure (or treatment) with more than two categories, or which is\ncontinuous, there are more than two potential outcomes for each individual. If the\noutcome is continuous, there are more than two possible outcome values.\nAfter we flip the coin, Sarah is assigned to one of the two possible treatments: active drug or placebo. Suppose the coin comes up heads, and so Sarah’s exposure\nis set to X = 1. We then follow Sarah for a year and measure her actual outcome.\nAt this point, we can safely assume that her factual outcome is equal to her potential outcome under X = 1, specifically Yx = 1. Her potential outcome under X = 0,\nhowever, will never and can never be known: Yx = 0 has become counterfactual—\nindeed, it became counterfactual at the moment of treatment assignment. While\nSarah’s potential outcome under X = 1 has become factual, her potential outcome\nunder X = 0 remains counter to fact: she was not (in fact) assigned to X = 0, and\nso Yx = 0 remains unknown. This illustrates a subtle difference in usage between\npotential outcomes and counterfactuals. Again, numerous investigators use these\nterms interchangeably, typically without introducing confusion.\n\n\n8.4.2.2 Individual Causal Effects\nNow that we have introduced the preceding notation and ideas, we can define the\nindividual causal effect of X for Sarah as the difference between (i) her potential\noutcome under assignment to X = 1 and (ii) her potential outcome under assignment to X = 0, or Yx = 1 − Yx = 0. In Sarah’s case, suppose that, after assignment to\nthe active drug, we discover that her outcome under that exposure was to live (i.e.,\nthat Yx = 1 = 0); and suppose we also know that had she been assigned to the placebo she would have died (i.e., that Yx = 0 = 1). Then her individual causal effect is\nYx = 1 − Yx = 0 = 0 − 1 = −1: the causal effect of treatment in Sarah is −1, the negative sign indicating that taking the active drug will prevent (rather than cause) the\ndeath she would have suffered had she (counter-to-fact) taken the placebo.\nWe have now defined an individual causal effect, but there is a problem with this\ndefinition. One of the two components in Sarah’s causal effect (Yx = 0) was counterfactual, and what is counterfactual was not observed in reality. Which means\nthat—except in made-up data—Sarah’s individual causal effect can never be known\nfor sure. We can guess at an individual causal effect under strong assumptions—\nwith our previous example of Jimmy who checked his text messages at an inopportune time, many people would feel comfortable betting on the idea that\nchecking his text messages caused his accident. But we cannot know for sure because at least one component of every individual causal effect is counterfactual\nand thus missing. It is for this reason that it is sometimes said that the “fundamental problem of causal inference” is missing data (Holland, 1986).\n\n\n8.4.2.3 Average Causal Effects\nWe cannot (in general) assess individual causal effects, but we can assess average\ncausal effects under additional conditions (see the later discussion in the section\n“Causal Identification Conditions”). Average causal effects (or population average\ncausal effects) are the average differences in outcomes comparing two treatments\nor exposures at the population level.\nContinuing with our example of a trial of a new long-acting drug versus placebo to prevent death within 1 year: like Sarah, each person in that study population has two potential outcomes, one under each treatment assignment, and each\npotential outcome could take on one of two possible values, alive or dead at the\nend of 1 year. In the whole population of N people, we can describe the number of\npeople with each combination of potential outcomes and values in a 2 × 2 table,\nas shown in Table 3.1.\nIn Table 3.1, A counts the number of people for whom the potential outcomes\nunder both X = 0 and X = 1 are equal to 1: these are people who will get the outcome (Y = 1) regardless of treatment (X = 1 or X = 0). Since the outcome is bad, we\nsometimes designate these individuals “doomed” to get the outcome (see Box 3.1).\nWho might such people be? Consider a person who dies in a car accident a week\nafter the trial begins and so is counted as an outcome in this trial: it is reasonable\nto assume that the car accident would have occurred and the individual would\nhave died regardless of whether that person had received active drug or placebo.\nSimilarly, D counts the number of people for whom both potential outcomes are equal to 0: these people are “immune” from experiencing the outcome because\nno matter the exposure they will not experience the outcome. B represents the\nnumber of people who will experience the outcome when unexposed but not\nwhen exposed and so those who are “protected” from the harmful outcome by\ntheir exposure, and C represents the number of people who experience the outcome only when exposed and are therefore “harmed” by their exposure.\nIn Table 3.1, an average causal effect could be calculated as the difference between (i) the proportion of people in the entire population who would experience\nthe outcome under exposure (X = 1), which is (A + C)/(A + B + C + D), and (ii)\nthe proportion of people in the same population who would experience the outcome under non-exposure (X = 0), which is (A + B)/(A + B + C + D). Using this\ninformation, we can calculate the average causal risk difference as:\nA C\nA B C D\nA B\nA B C D\n+\n+ + +\n−\n+\n+ + +\nwhich can be rewritten in terms of probability (Pr) of the outcomes as\nPr( ) Y Y x x = = 1 0 = 1 1 − = Pr( )\nor more simply as\nPr( ) Y Y 1 0 − Pr( ).\nThis is, simply, the difference between the risk of the outcome if everyone in the\npopulation were assigned X = 1 and the risk of the outcome if everyone in the\npopulation were assigned X = 0. We could further generalize this measure by expressing it in terms of expectations rather than probabilities (i.e., E(Y Y 1 0 ) E − ( )),\nwhich is a difference measure for any Y, including continuous-valued health\noutcomes such as weight or forced expiratory volume in 1 second.\nThe average causal risk ratio can likewise be written as\nPr Pr\n.\nY Y\nY Y\nx x\n= =\n=( )=\n( ) =\n( )\n( )\n1 0\n1 0\n1 1\nPr Pr\nThis 2 × 2 table of potential outcomes was built out of individual data—an\nindividual’s assignment to group A, B, C, or D depends on information about\nthe joint distribution of their potential outcomes, which we have already noted is\nunavailable to us. Recall that, in Chapter 2, we discussed how to estimate a risk\ndifference and risk ratio from observed data. In the next section, we address some\nconditions under which we can interpret such measures of association, estimated\nfrom real data, as estimates of causal effects.\n\n\n\n8.4.3 CAUSAL IDENTIFICATION CONDITIONS\nAs noted earlier, we cannot identify all potential outcomes because, at most, only\none potential outcome will ever be factually realized. However, we can assess\ncausal effects in real data if we assume (hopefully with good reason) that we have\nmet several causal identification conditions. Specifically, then, our goal is to understand what it takes to interpret an associational risk difference (or risk ratio,\netc.) such as\nPr( ) Y X = = 1 1 | | − = Pr( ) Y X 1 0 = ,\nas an average causal risk difference,\nPr( ) Y Y x x = = 1 0 = 1 1 − = Pr( ).\nThe causal identification conditions have received extensive treatments elsewhere\n(Greenland, 2017; Hernán & Robins, 2019). Here, we go over four key conditions\nwhich together are sufficient for identification of causal effects in real data. That is,\nwhen all four conditions are met, we can be reasonably assured that our measured\nassociation estimates the causal effect of interest. The key conditions we describe\nhere are temporality, causal consistency, exchangeability, and no measurement\nerror. We will also discuss conditional exchangeability with positivity as a substitute for the simpler exchangeability.\nAgain, we emphasize that this set of conditions is sufficient; it is not necessary\nfor all causal effect estimation. There are other sufficient sets of conditions as well,\nsuch as those used for instrumental variables (see Chapter 8). In the Appendix to this chapter, we show how these four causal identification conditions help us\nmake a causal interpretation from an association (i.e., considering the two equations immediately above, how we move from the first equation to the second).\nBefore we discuss these conditions, however, we must address an additional, vital\ncondition, or assumption, in the estimation of causal effects: identification of the\ntarget population.\n\n8.4.3.1 Target Populations and Study Samples\nAgain, our goal here is causal effect estimation from data. But, thus far in this\nchapter, we have not considered in which population we want to estimate the\ncausal effect. The target population is “the group of people about which our scientific or public-health question asks, and therefore for which we want to estimate the causal effect of an exposure,” according to Maldonado and Greenland\n(2002). This group is also frequently described as a source or base population\n(Porta, 2014).2 When we do not explicitly discuss a target, or source, population,\nit may seem reasonable to assume that the target population is the data we are\nanalyzing, which we call the study sample. In the real world, this is very often\nnot true.\nBriefly, consider a study of 1,000 people of how a new drug agent treats a disease compared to a placebo. The goal of such a study is almost never to estimate\na causal effect which only applies to those 1,000 people. Rather, the goal (quite\noften) is to obtain information that applies to all those individuals who might\nbe eligible to use the new drug agent under study. Likewise, we might perform a\nstudy in North Carolina, but want to know how those results apply to an external\ntarget population (people in South Carolina). We will discuss target populations\nfurther in Chapter 5 and Chapter 9. For the remainder of this chapter we assume\nthat our target population is exactly the data in front of us, that is that we wish to\nestimate causal effects only in our study sample.\n\n\n8.4.3.2 Causal Identification Conditions\nNow, we discuss the causal identification conditions. It is unlikely that these\ncausal identification conditions will be fully transparent to you the first time they\nare encountered: repeated exposure—to this chapter, to other sources (Hernán\n& Robins, 2019), and also to the way in which these concepts arise again in subsequent chapters on the study designs—is the surest route to increased understanding. So, don’t worry if the causal identification conditions are not entirely\nclear the first time you read them.\n\n\n8.4.3.3 Temporality\nTemporality is the condition that things which are causes precede their purported\neffects in time. If we wish to assess the effect of aspirin use on risk of heart attack,\nwe must be sure that study participants’ use of aspirin occurred prior to time of\nheart attack. Temporality might be violated when (for example) a study subject\nalready has the outcome at the time of exposure—for example, a participant has\nincipient liver cancer at the start of a randomized trial in which the outcome is\nliver cancer. Reverse causality is a particular manifestation of this phenomenon\nin which the (undiagnosed) existence of the outcome affects an individual’s exposure status; for example, in a study of the effect of smoking on lung disease\n(e.g., chronic obstructive pulmonary disease [COPD]), this might occur if early\nsymptoms of as-yet-undiagnosed COPD lead an individual to stop smoking.\n\n\n8.4.3.4 Causal Consistency\nCausal consistency, or sometimes simply consistency, is the idea that among people\nwho were exposed, their outcome was no different than it would have been if they\nhad been assigned that exposure—and the same is true for the unexposed. This\nidea is key in interpreting the observed outcomes as the potential outcomes: in\nthe chapter Appendix, we show how the application of causal consistency allows\nus to move one step from an association to an estimate of causal effect (Hernán\n& Robins, 2019).\nWhen can we assume that this condition is true? One crucial aspect of consistency relates to the question of whether there is meaningful variation in the\nobserved exposure or treatment. Suppose we want to know the effect of daily aspirin on risk of heart attack. For the exposure of “take aspirin daily,” we may view\ndose of aspirin (e.g., 81 mg vs. 162 mg) as meaningful variation in the exposure\nin that we could imagine a substantially different causal effect for each dose. At\nthe same time, we might view the issue of whether the aspirin is taken in the\nearly morning versus late at night as irrelevant; however, if we discovered that\nthe physiologic effects of aspirin differed substantially by whether you went to\nsleep immediately after taking the aspirin or not, then the latter variation would\nbe considered meaningful. Consistency, then, is in part the assumption that any\nvariations in the treatment or exposure being studied are irrelevant to the causal\nmechanism being studied: an idea often summarized as treatment variation\nirrelevance.\nQuestions of treatment variation irrelevance—of what constitutes a “meaningful” variation in treatment—is decided on a per-study, per-exposure basis,\noften after discussion among experts in the field. That said, this can become a\nparticular issue when considering health-relevant demographic attributes such\nas race, sex, gender, or socioeconomic status. While strong arguments can (and\nhave!) been made that all of these complex factors can be regarded as causes of\ndisease, what precisely “cause” means is difficult because each of these words\ncan mean various things depending on both speaker and context. For example, investigators often explore biological sex as a “cause” when they are in fact more\ninterested in effects due to gender or discrimination based on gender presentation\n(which is not the same as sex), or due to hormone levels (which vary with sex but\nalso with numerous other factors).\nLikewise, numerous studies in the literature examine differences in health\noutcomes by self-reported racial identity and then attribute part or all those\ndifferences to genetic differences between the races. However, genetic differences\nbetween races are extremely minor, and it is almost never the case that we can\nreliably attribute observed differences in health status to such minor genetic\ndifferences (Cooper, 2013; Kaufman, Cooper, & McGee, 1997).\nOne particular aspect of treatment variation worth calling out is interference,\nalso called dependent happenings or spillover effects. Interference is a situation in\nwhich my exposure has an effect on your potential outcome. Interference may be\nmost easily understood in an infectious diseases setting: consider a treatment of\nan influenza vaccine. If I am exposed to the influenza vaccine, this can easily have\nan effect on my daughter’s risk of acquiring influenza independent of my daughter’s\nvaccine status. This is because my being immunized may decrease her exposure\nto and thus risk of acquiring influenza. Indeed, the idea of herd immunity—that\nwhen sufficient numbers of people are vaccinated against a disease in a population, the nonvaccinated members of that population will be protected as well—is\nbased precisely on the existence of interference effects of this type. We can therefore expect the observed effects of this vaccine in a population to vary with the\nvaccine status of those around them: a form of treatment variation which seems\nhighly relevant. While interference is a serious consideration when it arises, we\nfrequently assume no interference as part of our consistency assumption and in\nnoninfectious diseases settings this is often a reasonable assumption. However,\nthere may be considerable spillover effects in infectious diseases settings, as well\nas with certain social phenomena.\nThere is at least one other use of the word “consistency” worth mentioning in\nthis context. In statistics and biostatistics, a consistent estimator of a particular\nquantity is one which converges to the true value of that quantity as the number\nof data points increases: this is distinct from causal consistency. Somewhat related, “no interference” is considered by some investigators to be equivalent to\nor a subset of the stable unit treatment value assumption (SUTVA; see Hernán &\nRobins, 2019, for a discussion). For discussion of the relation of consistency to the\nnotion of “well-defined interventions” see Box 3.2.\n\n\n8.4.3.5 Exchangeability\nExchangeability is informally the condition that study participants who are\nexposed (or treated) have the same average pre-exposure (or pre-treatment) risk\nof the outcome as study participants who are unexposed (or untreated). Here,\npre-exposure (pre-treatment) means “aside from any risk conferred by the exposure (treatment) itself.” An alternate formulation of the same idea is that, if there\nwere no causal effect of the treatment on anyone in the study, would the treated\nand untreated groups have the same average risk of the outcome? For example,\nin a study of the impact of a new drug on the outcome of heart attack, 40-yearolds would not (broadly speaking) be considered exchangeable with 60-year-olds\nbecause risk of heart attack increases with age—quite aside from the effects of\nthe drug under study. Another informal way to state this condition is that if exchangeability holds, then the risk of the exposed can stand in for the risk of the\nunexposed if—counter to fact—the unexposed had been exposed; and, similarly,\nthe risk of the unexposed can stand in for the risk of the exposed if—counter to\nfact—the exposed had been unexposed.\nFormally, the issue of exchangeability is about the statistical independence between the potential outcomes and the exposure or treatment actually received by\nparticipants in a study, which is typically stated as Y X x  for all values of x. For\ndichotomous Y and X this can also be written as Pr( ) Y Y x x | 1 X X = = = Pr( | 0),\nwhich states that the risk of Y for a set level of X (specifically, x) is the same\namong those observed to be treated and those observed to be untreated (Hernán\n& Robins, 2019). In the chapter Appendix, we show how the application of exchangeability, as with causal consistency, allows us to take an additional step from\nan association to an estimate of causal effect.\nWhen does exchangeability hold, or not hold? While we will discuss this issue at\nmore length in the later section on systematic error and in subsequent chapters, it\nis clear that, in a large population, random assignment of treatment (e.g., flipping a\ncoin to decide who receives treatment and who does not) will on average produce\nexchangeable samples. This is because over the long run, for every 60-year-old who\nis treated there will be a 60-year-old who is not, and, likewise, for every 40-year-old\nwho is treated there will be a 40-year-old who is not treated. So, on average, the\nproportions of 40- and 60-year-olds will be the same in the two groups, and so—\naside from any effect of the treatment itself—the average risk of the outcome will\nbe the same in the two groups as well. Lack of exchangeability, on the other hand,\nis generally due to the systematic errors confounding and selection bias and is often\nwhat people mean when they repeat the statement that “correlation is not causation”—although we are quick to remind you that correlation is not not-causation, as\nwell. These systematic errors are discussed in greater depth later.\nAgain, we are satisfied that the exchangeability assumption is met sufficiently to\nestimate an average causal effect if pre-treatment risks (i.e., the potential outcomes\nin absence of exposure) in our two comparison groups are the same on average.\nNote that individual causal effects—though we cannot estimate them—would\nlikewise meet the exchangeability condition as well, in that any individual at a\nparticular moment in time has the same baseline risk of an outcome whether they\nare treated or untreated immediately thereafter.\n\n\n8.4.3.6 Conditional Exchangeability\nIn observational studies, the reasons that individuals wind up exposed (either by\nchoice or by circumstance) frequently involve exactly those factors which also\naffect the affect risk of the outcome. Thus, in observational settings, the average pre-exposure risk among those who are exposed is not (in general) the same as\nthe average pre-exposure risk among those who are not exposed. For example, as\nearlier, if 40-year-olds are more likely to start smoking than 60-year-olds, then the\nsmokers are not exchangeable with the nonsmokers (and we would say that the\neffects of smoking are “confounded by age,” see later discussion). Here, when average pre-treatment risk of the outcome is not the same across exposure groups, we\nmust try to deal analytically with variables like age. If we can meet exchangeability\nafter accounting for (conditioning on) additional variables such as age, we call\nthis conditional exchangeability. The formal statement of conditional exchangeability is only slightly different from the formal statement of exchangeability noted\nearlier: specifically, Y X x  | Z for all values of x, where Z is all relevant covariates\n(in our example in this paragraph, age; see Hernán & Robins, 2019).\nTo explain further: recall from above that exchangeability implies that the risk of\nthe exposed can stand in for the risk of the unexposed, if—counter to fact—the unexposed had been exposed (and vice versa). Conditional exchangeability says similarly\nthat the risk of the exposed can stand in for the risk of the unexposed, conditional on\ncertain additional variables, if—counter to fact—the unexposed had been exposed\n(and vice versa). Back to our populations of 40-year-olds and 60-year-olds, it might\nbe that the risk of exposed 40-year-olds can stand in for the risk of unexposed 40-\nyear-olds, had those unexposed 40-year-olds in fact been exposed and, likewise,\nthat the risk of exposed 60-year-olds can stand in for the risk of unexposed 60-yearolds had those unexposed 60-year-olds in fact been exposed and so on. The identification and choice of variables for conditional exchangeability based on causal\ndiagrams will be explained later, in Section 3.4 on causal diagrams and confounding.\n\n\n8.4.3.7 Positivity\nBut what if there were no exposed 60-year-olds in our study—if the only exposed\npeople were 40-year-olds? Conditional exchangeability introduces new variables\nto our system, and the need to deal with other variables introduces another condition to be met, namely positivity. Informally, positivity is the condition that\nall subjects must have a non-zero chance of receiving either treatment under\nstudy: in this case, 40-year-olds must have a nonzero chance of both initiating\nand not initiating smoking, and the same must be true for 60-year-olds. Positivity\nis about the relationship of the exposure to the variables required for conditional\nexchangeability—thus, once we have chosen the set of variables necessary for conditional exchangeability, the outcome is no longer part of the discussion of positivity. The close linkage between these two conditions sometimes leads us to refer\nto them jointly as conditional exchangeability with positivity.\nThe formal statement of positivity condition is Pr(X x = = | 0 Z z) > , where Z\nis all covariates used for conditional exchangeability, and z is all combinations\nof those covariates present in the data under study (Hernán & Robins, 2019).\nThus, there must be a greater than zero probability of any treatment or exposure\ncondition for all observed combinations of the covariates relevant to conditional\nexchangeability.\nBroadly, there are two essential ways in which we might lack positivity: structural (or deterministic) and stochastic. In structural nonpositivity, there is a segment of the population under study which has no opportunity for exposure for\nstructural (e.g., physical) reasons: if we are asking about the effect of hysterectomy\non some later health outcome, then study subjects who lack a uterus cannot experience the exposure. In this case, the best course is likely to exclude such subjects\nfrom an estimate of causal effect—there is no reason to ask the question of the impact of a hysterectomy in these subjects in the first place. Stochastic nonpositivity\nis a data, rather than structural, phenomenon. For example, we might have a population in which by chance no one under the age of 50 is a smoker, and everyone\nover the age of 50 is a nonsmoker. While there is no physiologic barrier to being\na smoker under age 50, in such a population it becomes difficult (though not impossible) to separate effects of smoking and age.\n\n\n8.4.3.8 No Measurement Error\nNo measurement error is not broadly discussed as a causal identification condition, but it is worth noting here (and it is useful in the chapter Appendix as well).\nIf the exposure or outcome (or covariates required for conditional exchangeability) is measured with error, we sometimes cannot estimate a valid causal effect even under otherwise ideal conditions—for example, a perfectly conducted\nrandomized trial that ensured temporality, unconditional exchangeability, and\nconsistency (see Chapter 5). We therefore regard lack of measurement error as a\nhelpful condition for causal effect estimation, although there are rare cases when\nmeasurement error can actually be helpful (see quasi-experiments in Chapter 6).\nWe add briefly that one can view treatment variation irrelevance (consistency) as\nan issue of measurement error. If the exposure is defined as “takes any amount\nof aspirin daily,” then both 81 mg and 162 mg doses of aspirin are valid. But if\nthe exposure of interest is really “one 81 mg aspirin daily,” then the classification of 162 mg of daily aspirin as “exposed” is in fact misclassification, a type of\nmeasurement error\n\n\n8.4.3.9 Summary\nThe preceding conditions—temporality, consistency (primarily treatment variation irrelevance, including no interference), exchangeability (or alternatively conditional exchangeability with positivity), and no measurement error—are useful,\nthough not strictly necessary (Greenland, 2017), for nonparametric identification of causal effects from data.3 Practical considerations, such as the “curse of\ndimensionality,” often force us to make additional assumptions encoded in statistical models to estimate effects. The chief such assumption is that such models are correctly specified (Keil et al., 2018). Machine learning approaches can help\nus ensure correct model specification with far fewer assumptions, though they\nmay introduce additional statistical issues (Naimi & Balzer, 2018; van der Laan\n& Rose, 2011).\nWhen treatment is randomized, it is often reasonable to assume that many or\nall of these conditions are met, for reasons we will discuss in Chapter 5. In such a\nsetting, one can usually estimate causal effects for the study sample from a pair of\nsurvival curves or a simple 2 × 2 table and be reasonably confident in the validity\nof those estimates. However, when treatment is not randomized, we often do not\nknow whether we have met these conditions—perhaps most centrally whether\nwe have met conditional exchangeability. In such settings, if we wish to interpret measures of association estimated from data as causal effect estimates, we\nmust assume that these conditions hold: in this case, we would assume that we\nhave conditional exchangeability given certain variables. One way to be transparent about such assumptions is to encode some of them in a diagram of your\nhypothesized causal system.\n\n\n\n8.4.4 CAUSAL DIAGRAMS\nCausal diagrams were introduced into mainstream epidemiologic literature in\n1999, in a paper by Greenland, Pearl, and Robins (1999) and are a useful tool for\nthinking through questions of systematic error in a study, particularly questions\nof (conditional) exchangeability. Here, we concentrate on a particular type of\ncausal diagram called causal directed acyclic graphs (alternatively, DAGs or causal\nDAGs), although single-world intervention graphs (SWIGs) are also a useful technology for causal effect estimation and additionally map more directly onto potential outcomes than do causal DAGs. In this section we introduce DAGs and\nexplain briefly how to use them to identify conditional exchangeability.\nDAGs are simply a collection of nodes (representing variables) and singleheaded arrows connecting those nodes (directed arrows connecting nodes into\na graph), where there are no cycles of arrows (you cannot start at a node, follow\narrows, and return to the same node). Arrows indicate causal relationships: an\narrow from X to Y indicates that X is a cause of Y (and therefore that changing X\nmay change Y). DAGs explicitly forbid double-headed arrows.4\nFor example, if we wish to know the effect of X on Y, we would start by drawing\na node labeled X, a node labeled Y, and a single-headed arrow from X to Y\nindicating the possibility of a causal effect of X on Y (specifically, the possibility\nthat intervening to change X will result in a change in Y; Figure 3.1, left). In most\ncases, we understand the nodes X and Y to be random variables representing\nvalues taken on by an individual; thus X and Y in Figure 3.1 could both have an i\nsubscript indicating that they are individual variables. However, such a subscript\nis typically omitted.\nFrom this base, we create other nodes for other variables we believe to be relevant\nto the X→Y relationship (see Box 3.3): for example, we could include a joint cause\nof both X and Y and call it Z. We draw a node for Z and then draw single-headed\narrows from Z to X (Z is a cause of X) and from Z to Y (Z is a cause of Y) (Figure\n3.1, center). We might expand that figure to include an additional possible pathway\nbetween X and Y that includes a new variable, M, and finally add in the idea that X\nand Y both affect (i.e., cause) some additional variable, C (Figure 3.1, right).\nWe now have a rich enough diagram (Figure 3.1, right) to introduce some terminology: Z in this causal DAG is generally considered a confounder of the X→Y relationship and compromises exchangeability if we wish to estimate the effect of\nX on Y. Specifically, Z is a confounder because it sits on an open backdoor path\n(see Section 3.5.1).\nC is called a collider on the path X→C←Y because two arrowheads collide (→←)\nin node C; we will explain colliders later, but they should be sharply distinguished\nfrom confounders.\nFinally, M is called a mediator on the path X→M→Y. M mediates the X→Y\nrelationship, in that part of the effect of X on Y flows through M (follow the\narrows!). Understanding that M is a mediator of the X→Y relationship allows us\nto distinguish several types of causal effects. The total effect of X on Y comprises\ntwo pathways: the pathway X→Y and the pathway X→M→Y. The direct effect of\nX on Y not mediated by M is the first of these alone; an indirect effect of X on\nY through M is the second alone (although we do not often frame effects this\nway). Identification of a direct effect therefore requires us to propose one or more\nfactors that the effect of exposure is mediated by, in this case M. There are entire\ntextbooks (VanderWeele, 2015) dealing with mediation of causal effects; we only\ntouch on basics here.\nIt is important to emphasize several points. First, the absence of an arrow between two nodes on a DAG corresponds to a strong assumption that there exists\nno causal relationship between those two nodes for any individual. This condition\nis called the sharp causal null and is a stronger assumption than the average causal\nnull. An average null effect could result from a cancelling of positive and negative\nindividual effects. In Figure 3.1 (right), for example, the absence of an arrow from\nZ to M is a strong assumption that Z does not affect M for any individual. Since it\nis frequently difficult to recognize things (in this case, arrows) that are absent, this\nrepresents a substantial cognitive tripping hazard with the use of DAGs.\nSecond, DAGs are scale-independent: the same DAG applies whether you are\nconsidering a risk difference or a risk ratio, for example. And, as such, DAGs are\nof somewhat limited utility when considering effect measure modification (see\nChapter 5 and Chapter 6).\nFinally, we noted earlier that no causal loops are allowed: this is to preserve\ntemporality in assessment of causal effects from a DAG. For example, it is plausible that weight affects a decision to start smoking and that initiation of smoking\nmay then affect future weight. But if this causal chain is expressed as a diagram\nlike Figure 3.2 (upper panel), in which same variable (Weight) appears twice,\nthen the causal diagram appears to violate temporality. Weight is measured at a\npoint in time, and it is not possible for future smoking to affect weight in the past.\nDAGs can address this problem by time-indexing nodes: thus, the lower panel of\nFigure 3.2 expresses the underlying ideas with greater clarity (and without an implied causal loop).\nNext we describe types of systematic error, frequently using DAGs to illustrate\nthese concepts. This might be a good moment for you to refresh your understanding of the differences between systematic and random error (Chapter 1).\n\n\n8.4.5 THE VARIETIES OF SYSTEMATIC ERROR\nIn this book, we divide the types of systematic error into four types: confounding\nbias, missing data bias, selection bias, and measurement error (or information bias;\nmisclassification is a special case of this). There are certainly ways to quibble with\nthis taxonomy.5 Nonetheless, we view these categories as useful for introducing\nthese concepts. We use causal DAGs to illustrate several of these biases and to\nexpand and illustrate additional concepts. Informally, by “bias” we mean any difference between the true causal effect and the expected value of the causal effect\nestimated in our data, where by “expected” we mean “not due to chance alone.”\nAs with the causal identification conditions, it is unlikely that all these ideas\nwill be fully transparent to you the first time you encounter this material, in part\nbecause these concepts are difficult and may require multiple exposures. Another\nfactor is that several of these biases—especially confounding—are concepts which\nare clarified by comparing their occurrence between study designs. Confounding\nin particular will generally not occur in a randomized trial (though this depends\nin part on what analysis is performed using trial data; see Chapter 5) but will generally arise in an observational cohort study (see Chapter 6). Likewise, selection\nbias may be more understandable after comparing and contrasting observational\ncohort studies (again, Chapter 6) with case-control studies (Chapter 7).\nThus, we believe that the best way to learn these concepts is to iterate: read the\nfollowing section; read on in the book; and then, when you encounter these ideas\nagain, circle back to this section (and this chapter as a whole) and refresh yourself on these ideas. Thus, in the remainder of this section, we seek (i) to introduce\nthese ideas so you will have a basis for understanding these ideas when they arise\nlater in the work (especially in Chapters 5–7) and (ii) provide a reference for you\nto come back to when reading those chapters to clarify these concepts.\n\n8.4.5.1 Confounding Bias\nConfounding bias is what is nearly always meant by the statement “correlation is not causation” and is one name for a lack of exchangeability, specifically\nnonexchangeability due to the imbalance of (typically) causes of the outcome across levels of the exposure. To be free of confounding bias, the only association\nbetween the exposure and the outcome must be due to the exposure itself, whose\neffect we wish to estimate. Confounding variables create such other associations\nbetween the exposure and the outcome: for example, in Figure 3.3, V creates an\nassociation between X and Y which is not the causal effect of X on Y. Such a situation maps neatly to our informal understanding of exchangeability: if V causes\npeople to be exposed (V→X) and V causes the outcome (V→Y), then the preexposure risk of Y among those with X = 1 is likely to be different from the preexposure risk of Y among those with X = 0.\nThe classic (but problematic) definition of confounding states that a confounder\nis a variable which is (approximately) associated with the exposure and outcome\nand not caused by the exposure. This definition leaves room for subtle errors, especially those involving colliders (e.g., M-diagrams; Greenland, 2003). Addressing\nconfounding—identifying confounders—from the perspective of causal DAGs\nsolves several problems with more classic definitions of confounding although\nnot without introducing additional complications.\nUsing a DAG, we identify the confounding variables—the variables that are\nleading to nonexchangeability—in the following steps (Greenland, Robins, &\nPearl, 1999):\n1. Remove all arrows that begin at the exposure.\n2. Identify the backdoor paths: that is, paths which\na. begin with an arrow into the exposure, and\nb. end with an arrow into the outcome.\n3. For each backdoor path, determine whether the path is open or closed.\nPaths are open unless\na. they contain one or more colliders, and\nb. we have not conditioned on those colliders (see below, and section 3.5.3).\n4. All open backdoor paths are considered confounding paths; all variables\non such paths (except the exposure and outcome) are considered\nconfounders.\nWe have now identified all open backdoor paths, and thus confounders, in our\ndiagram. We then achieve independence of the exposure and the outcome by “controlling” or “adjusting” for confounding variables, thus “closing” those otherwise open paths. What does it mean to control confounding, in practice? We might\nmean, for example, “include the confounder in a regression model” or “account\nfor the confounder using standardization”: we return to these ideas later in this\nbook (Chapter 6). Here, we focus on the decision of which variables we will adjust\nfor. We add that if we condition on a collider (3b, in the steps above) we open an\notherwise closed path, a concept we explain further below (see Selection Bias).\nConsider a few examples. In Figure 3.3, we would begin by removing the\narrow from X to Y. This leaves two backdoor paths, both open (X←V→Y and\nX←G→Y): to close all backdoor paths, we would need to control (again, for now\nwe do not specify how we will do this) for V and G.\nIn Figure 3.4, removing the X to Y arrow leaves two paths. There is one backdoor path (X←Z→Y) and one closed path containing a collider (X←T→S←Y; remember that S is a collider on this path because the arrowheads from T and Y\n“collide” in that node). To close all backdoor paths in Figure 3.4, we would have\nto condition on Z, but we can leave the X←T→S←Y path alone, as it closed by the\ncollider. If we were to condition on S, we would open this path.\nFinally, in Figure 3.5, there is a single open path (X←Q→E→Y): to close this\npath, we can condition on Q, or on E, or on both Q and E. In this last example,\nthere are three sufficient sets of covariates [Q; E; Q and E]; controlling for any of\nthese three sets will remove the confounding of the X→Y relationship.\nOf critical importance is that we can never know whether a causal DAG has\nfully captured the real causal process, including all confounders of the causal relationship we want to estimate. It is always possible that, for a given DAG, there\nmight be a variable (often designated U for unknown or unmeasured) which (for\nexample) has arrows into both X and Y and therefore confounds their relationship. If such a U exists, then controlling for confounding based on the DAG will\nnot deal with all biases of the causal relationship under study. It is in general impossible to rule out the existence of such a variable—except in an intention-totreat analysis of a properly conducted randomized trial (see Chapter 5). Finally, as\na note, we remind you that this is just a very preliminary introduction to DAGs.\nWe will discuss these methods further later in this book, but the book as a whole is only an introduction to these methods. More details can be found in works by\nHernán and Robins (Hernán & Robins, 2019) and Pearl (1995, 2009).\n\n\n8.4.5.2 Missing Data\nMissing data bias results from lack of complete information on exposure,\noutcomes, or covariates in a study. For example, if, in a study of 100 participants,\n20 did not have an exposure status recorded, we would describe that situation as\nmissing exposure data.\nGenerally, we think of missing data in three main categories: missing completely at random, missing at random, and missing not at random. Missing completely at random (MCAR) data are missing exactly as you think: completely at\nrandom, as if the data which are not missing are a simple random sample of the\nfull data. If 10% of outcome data are missing completely at random, for example,\nit is the same as saying that for each individual we rolled a fair 10-sided die, and, if\nwe roll a 7, then we replace their outcome with a “missing” indicator. Data might\nbe missing completely at random if a gust of wind caused a stack of unordered test\nresults on paper to be blown away, and some sheets of paper were swept into a lake\nand destroyed before they could be recovered.\nData which are truly MCAR are rare: more common are data missing at random\n(MAR). MAR is a confusing name, sounding too much like MCAR to be clearly\ndistinguished by the language. MAR indicates data which are missing independent of the missing data itself, conditional on the observed data for each individual. For example, if exposure is fully observed in all participants, and outcome\nis missing in 10% of participants who are exposed and 20% of participants who\nare unexposed, and missingness does not depend on any other variables, then we\nwould conclude that outcome data are MAR.\nData missing not at random (MNAR) are missing data which are neither MCAR\nnor MAR, and therefore those where the missingness depends on the unobserved\nvalue of the missing variable itself. Age would be MNAR if age were missing more\noften in older people than in younger people.\n\n8.4.5.2.1 Analysis with Missing Data\nThe most common way of addressing missing data is to perform what is called\na complete case analysis, in which only those observations which have full data\navailable are analyzed. For example, consider an analysis of the effect of exposure\nX on outcome Y controlling for covariates Z1, Z2, and Z3. Complete case analysis would include only those individuals who had no missing data for any of those\nfive variables.\nSuch an approach, however, may lead to biased estimates. Under what\ncircumstances does a complete case analysis result in bias? Broadly, this is a\nproduct not of information structure (e.g., MAR/MNAR distinctions) but of\ncausal structure. In particular, we can have situations of both MAR and MNAR\nin which there is no bias in complete case analysis and also situations of both\nMAR and MNAR in which there is bias in complete case analysis. However, since\nMCAR data are independent of the outcome (and all other observed variables),\ncomplete case analysis of MCAR data is generally unbiased. (Daniel, Kenward,\nCousens, & De Stavola, 2012).\nWe demonstrate some of these issues in simple examples, using the three\nDAGs in Figure 3.6 and accompanying data in Table 3.2. In Figure 3.6, R = 1\nwith a box around it indicates that we have restricted analysis to individuals who have no missingness on X or Y (R for response). In the left panel, R is\nindependent of both X and Y. In Table 3.2, the top 2 × 2 table (labeled Full)\nis example data without any missingness, and the second 2 × 2 table (labeled\nLeft) corresponds to Figure 3.6 (left). In Table 3.2 (Left), 20% of the full table\nis missing in every cell, equally: so instead of 200 exposed disease cases, we see\n160, and we estimate the same exposure-specific risks (and same risk difference)\nas in the Full data.\nIn the center panel of Figure 3.6, things are more complicated: there is an\nopen path from R to Y (R←X→Y). The 2 × 2 table in Table 3.2 (Center) shows\nmissingness which differs by level of X; 50% of those with X = 1 are missing, but\nonly 20% of those with X = 0. In this table, we see that the exposure-specific risks\nare estimated accurately from the data, and therefore we can estimate the correct\nrisk difference from those exposure-specific risks. This is because the open path\nbetween R and Y is closed conditional on X (see below).\nIn the right panel of Figure 3.6, we show missingness differential by level of Y,\nbecause Y→R. The last 2 × 2 table in Table 3.2 (Right) shows missingness which\ndiffers by level of Y: 10% of those with Y = 1 are missing, and 50% of those with\nY = 0. The exposure-specific risks here are incorrect and so is the risk difference\n(about 0.14), showing the bias that can arise when missingness is caused by the\noutcome as in the right panel of Figure 3.6.\nWe make three brief points. First, note that there is no bias in the risk difference\nfor Figure 3.6 (center) but there is bias in the risk difference for Figure 3.6 (right),\nas is evident in Table 3.2. Now recognize that X→R in Figure 3.6 could mean that\nthe true value of X is the cause of missingness in X (which would mean the data are\nMNAR) or of missingness in Y (which would mean the data are MAR). Similarly,\nrecognize that Y→R in Figure 3.6 could mean that the true value of Y is the cause\nof missingness in Y (which would mean the data are MNAR) or of missingness\nin X (which would mean the data are MAR). Thus, we have demonstrated that\nwhether data are MAR or MNAR does not tell you whether or not there is bias in\ncomplete case analysis. (Daniel, Kenward, Cousens, & De Stavola, 2012).\nSecond, key to understanding causal diagrams for missing data is the independence of missingness and the outcome (Daniel, Kenward, Cousens, & De Stavola,\n2012). For example, the reason there is no bias from Figure 3.6 (center) is that\nwhen we condition on X (i.e., within levels of X), there is no association between\nmissingness and the outcome. On the other hand, analysis of the total incidence\nof the outcome (which is not conditional on X) in this diagram will be biased: the\ntotal incidence of Y = 1 in the Center table ((100 + 80)/(500 + 800)) is biased\ncompared to the full table ((200 + 100)/(1,000 + 1,000)). And third, and closely\nrelated, all these issues become much more complex when confounders are added\nto diagrams: such complexities are beyond the scope of this book and are the subject of ongoing methodological work. Here, we want you to come away with the\nbasic understanding that MAR and MNAR are not the same as biased or unbiased\nin complete case analysis, as we have demonstrated.\nSo what, then, is the use of MAR and MNAR distinctions? They tell us when—\nunder missing data—we can correct for any bias that exists or improve the precision of our estimates using more advanced analytic techniques such as multiple imputation (Little & Rubin, 2002) or inverse probability weighting (Hernán &\nRobins, 2019). Specifically, multiple imputation and other methods generally depend on data being MAR (or MCAR) rather than MNAR. When data are MNAR,\nsuch techniques cannot be expected to eliminate all bias due to missing data. Of\ncourse, just as we can never know whether uncontrolled confounding is present\n(e.g., if we have left a critical covariate out of our DAG), we can never know for\ncertain whether missing data are missing at random or not at random (i.e., are\nmissing at least in part due to the unobserved true values of the given variables).\nWe summarize some of this information in Table 3.3.\nTherefore, in the left and center panels of Figure 3.6, complete case analysis for\nthe effect of X on Y (again, analysis of only those participants with no missing\ndata on any variable) will be unbiased due to the missing data; however, multiple\nimputation, if possible, might improve the statistical efficiency (i.e., the precision)\nof the estimate. In the right panel of Figure 3.6, the complete case analysis will be\nbiased, but multiple imputation (or a related technique) might be able to reduce\nthe bias if the true value of Y is leading only X to be missing. We omit discussion\nof how to implement multiple imputation and inverse probability of missingness\nweighting; readers can find such discussions elsewhere.\n\n\n\n8.4.5.3 Selection Bias\nIn epidemiology, the term “selection bias” means several things depending on\ncontext. These include bias resulting from the noninclusion of study subjects in\nanalysis, for example, because of loss-to-follow-up (out-selection); bias resulting\nfrom conditioning or restricting on a collider (collider selection bias; Hernán,\nHernández-Díaz, & Robins, 2004); and bias resulting from the selection of\nsubjects into a study (in-selection bias, sampling bias, or generalizability bias). In\nthis work we distinguish the three while acknowledging that all three are reasonably called “selection bias” by epidemiologists (Hernán, 2017).\nThe first form of selection bias we discuss is analytic selection bias, which\nincludes selection bias due to loss to follow-up and which overlaps with issues\nof missing data in some cases. In particular, when we analyze only cases with\nno missing data (described earlier as complete case analysis) the two can coincide: cases with no missing data are selected for analysis; those with missing data\n(leading to non-analysis) are not selected. As with missing data, we can analyze\nwhether selection is likely to lead to bias by using DAGs (such as Figure 3.6) and\nsometimes adjust for selection using analytic techniques (see Table 3.3).\nThe second type of selection bias is due to conditioning or restricting on a collider, called collider bias. Recall that a collider is a variable which is jointly caused\nby two additional variables (e.g., node C in Figure 3.7). For example, your steps\nmay be wet because it rained or because the sprinkler system has a timer—the\nwetness (or not) of the steps is a collider for rain and the sprinkler. While X affects\nC and Y also affects C (X→C←Y) it is possible that there is no direct relationship\n(or arrow) between X and Y, as in Figure 3.7 (left).\nAnother example: if smoking affects risk of heart attack and so do the genetics\nof cholesterol metabolism, there may not be a direct relationship between genetics and smoking. But among those who have a heart attack (where C = 1, a\nform of conditioning on the node C) there may be a relationship between the\ntwo nodes. This is because among those who have a heart attack, there is often a\nreason; among those who have a heart attack (C = 1) who do not smoke (X = 0),\nthose reasons are more likely to be genetic than for in others in the population.\nThus, in those individuals who have had a heart attack, knowing that they do not\nsmoke raises the probability that they have some genetic susceptibility to heart attack. This induced relationship between smoking and genetics after conditioning\non heart attack is sometimes informally shown on a DAG as a dotted line between\nX and Y. This is illustrated in Figure 3.7, in which, unconditional on C, there is\nno relationship between X and Y (left); once we condition on C (right; the box\naround C indicates we are holding C constant at any level), we induce a noncausal\nassociation (shown as the dotted line) between X and Y.\nCollider bias is sometimes considered a form of selection bias (Hernán et al.,\n2004); but see also (Hernán, 2017) though others find this use of “selection” somewhat confusing. Frequently, to “select” something is to pick that something out.\nwhile leaving other things behind. While some forms of collider bias (particularly, restricting on a collider) coincide with this connotative usage, other uses\n(conditioning on C in X→C←Y as in the right panel of Figure 3.7) do not match\nup with typical and widespread uses of the word “selection,” leading to some confusion. Whatever it is called, however, conditioning on a collider can lead to dramatically incorrect study conclusions, including several issues that are otherwise\nconsidered “paradoxes” (Hernández-Díaz, Schisterman, & Hernán, 2006; Stovitz,\nBanack, & Kaufman, 2018).\nThe last common use of selection bias is in-selection bias, which is a problem\nof the generalizability of findings from a study to some external target population (see Chapter 9for further discussion of target populations). This might occur\nif, for example, the results of your study vary by age, and the distribution of age\ndiffers between your study sample and your target population. While calling this a\nkind of selection bias is a perfectly reasonable approach and matches up well with\nbroad usage of “selection,” in this work we will distinguish this manifestation of\nselection bias by referring to it as generalizability-bias or sampling bias.\n\n\n8.4.5.4 Information Bias\nHere, we consider “information bias” and “measurement error” to be interchangeable terms and “misclassification” to be closely related. Errors of this type can\narise for numerous reasons—and can lead to bias even when the error is entirely\nrandom.\nInformation bias is in some ways easiest to understand when considering a\ntwo-category variable—for example, “exposed” and “not exposed”—and how\nindividuals in one group may be mislabeled as belonging to the other group.\nThis is a special case of measurement error we call misclassification. Consider\nthe 2 × 2 table shown in Table 3.4 (top), which we presume tells us the truth\nabout the world: in particular, that the risk difference (for some fixed time period) comparing exposed to unexposed is 0.10 − 0.05 = 0.05. Now suppose\nthat we have a flawed test for assessing exposure, which randomly misclassifies\n20% of all truly exposed individuals as unexposed (i.e., the test has a sensitivity of 80%, see Chapter 4).However, this test never misclassifies the unexposed people. In this case, we would observe a table in which 20% of the truly\nexposed individuals (with their outcome risk of 10%) are analyzed as if they are unexposed: this is the equivalent of moving 200 individuals total, of whom\n20 experienced the outcome, from the exposed to the unexposed group and\nreanalyzing the data (Table 3.4, bottom). This leads to the overall risk of the outcome in the unexposed group being estimated at about 5.8%, rather than 5%—\nand that in turn leads to a biased estimate of the causal effect, which will now\nbe estimated as 0.100 − 0.058 = ~4.2% instead of 5%. Thus, misclassification of\nthe exposure leads to bias in this case; we encourage you to create your own example misclassifying the outcome (e.g., taking 10% of those within the Outcome\ncolumn and shifting them to the No outcome column, the same way in each\nrow) to see what happens.\nTable 3.4 presents an example of nondifferential misclassification of the exposure, which in the case of two categories will tend (on average) to move the effect\nestimate toward the null value of the effect in question (i.e., toward 0 for a risk\ndifference, or 1 for a risk ratio). The misclassification here is “nondifferential”\nbecause the probability of being misclassified is independent of the true outcome\nstatus. The bias toward the null (e.g., a risk difference closer to zero) is due to\nthe fact that moving individuals randomly from exposed to unexposed (or vice\nversa, or both at once) will tend (on average) to make the two groups more similar. At one possible extreme, when the exposed/unexposed label is assigned at\nrandom, irrespective of true exposure, the two groups will have the same proportion of exposed and unexposed participants, and we will detect no differences\nbetween them. It should not surprise us, therefore, that as two groups become\nmore similar due to misclassification, the differences between them tend to grow\nsmaller.\nThis idea that “nondifferential misclassification of the exposure will lead to bias\ntoward the null” is widely repeated and often misunderstood in its particulars,\nand so it is worth examining more closely. First, and most critically, this is a statement about averages: while the direction of the bias is predictable, in any given\nexample or dataset the realization of nondifferential misclassification is subject\nto random as well as systematic error. Such random error may lead to data in\nwhich supposedly nondifferential misclassification leads to bias away from the\nnull (Jurek, Greenland, Maldonado, & Church, 2005). As well, if there are more\nthan two exposure categories, the direction of bias resulting from nondifferential\nexposure misclassification is unpredictable. Finally, when misclassification is differential, all bets are off: if (for example) exposure was misclassified only among\nthose who experienced the outcome, or at different rates among those who had\nthe outcome and those who did not, the direction of bias would be generally\nunpredictable.\nInformation bias generally can result from a number of processes, including\nsystematic bias in collection of information or faulty instrumentation. It is an\nimportant form of systematic error, especially because measurement error that\noccurs completely at random can introduce bias into effect estimates. For example,\nif random noise makes two distinct groups look more similar, then comparisons\nbetween those groups may be attenuated. We describe approaches to addressing\ninformation bias in Chapter 4.\n\n\n8.4.5.5 Internal and External Validity\nHaving now discussed both the notion of a study sample compared to a target\npopulation and the biases which can arise, we can discuss the notions of both internal validity and external validity. Recall from Chapter 1 that validity is defined\nas a lack of bias, or lack of systematic error such as those just described. Assuming\nfor the moment that we have no random error, we can define internal validity as\nthe condition in which we have no bias in our estimate of causal effect within the\nstudy sample: that is, when the estimated causal effect in the study sample is equal\nto the true causal effect in the study sample. This condition is shown more formally\nat the end of the Appendix to this chapter.\nIn contrast, there is external validity when the true effect in the study sample is\nequal to the true effect in the target population, or alternatively when “the [true]\ncausal relationship holds over variation in persons” (Shadish, Cook, & Campbell,\n2002, p. 472) and perhaps other factors. In cases where the target population is\nexactly equal to the study sample, there is perfect external validity. For the most\npart in this book, we focus on estimating internally valid causal effects, but we\ndiscuss external validity in several places as well. Discussion of the relationship\nbetween internal and external validity is ongoing in the methodological literature\n(see Westreich, et al., 2019).\n\n\n\n8.4.6 MEASURES OF CAUSAL EFFECT\n\n8.4.6.1 Measures of Effect\nWe now briefly return to the measures of association we described in Chapter 2.\nRecall that all the measures of association discussed in Chapter 2 can be estimated\nwithout attention to the causal identification conditions and biases/systematic\nerrors noted earlier, but then the resulting estimates can only be interpreted as\nassociations and not as estimate of causal effect.\nFor example, we can estimate a risk difference from an observed 2 × 2 table of\ndata even if exchangeability is not met in the data, specifically if the exposure–\noutcome relationship is confounded. However, if the exposure–outcome relationship is confounded, we can only interpret that risk difference as an association\nbut not as a causal effect. If we wish to interpret an estimated risk difference as an\nestimate of a causal effect, we should be prepared to defend why we think the risk\ndifference in question meets the causal identification conditions noted earlier or\ncan be considered causal for some other reasons (e.g., meets an alternative set of\nidentification conditions). Earlier, we showed how application of some of these\nconditions allows us to connect the association with the estimated causal effect for\nthe risk difference; similar processes can be applied to the risk ratio, odds ratio,\nand other measures of association explored in Chapter 2.\nNow we discuss two measures which were not covered in Chapter 2 because\nboth can be viewed as more inherently causal measures and cannot be easily or\nsensibly interpreted in terms of association alone. These are the number needed to\ntreat (NNT) and the population attributable fraction: these should be calculated, reported, and interpreted only when we can make a reasoned argument that they\ncan be interpreted causally—and otherwise only with extreme caution.6 (See\nChapter 9 for further discussion of both measures.)\n\n\n8.4.6.2 Number Needed to Treat\nConsider a new pharmacotherapy (“Treatment”) to prevent heart attack (myocardial infarction, MI) in older adults, in a study lasting 5 years. Data for this\nstudy are shown in Table 3.5, where those not taking the treatment have a 10%\nrisk of MI over 5 years, while those taking the treatment over that period have a\n6% risk. We could use these numbers to calculate the 5-year risk difference associated with treatment (0.06 − 0.10 = −0.04) and likewise we could calculate a risk\nor odds ratio.\nSuppose instead we wish to ask “How many untreated people would we have to\ntreat in order to prevent one MI?” This is the number needed to treat, and it is selfevidently about causality: we are asking not about associations, but about the likely\neffects of making a change in the world by treating people with a specific drug.\nThe NNT is calculated as simply the reciprocal of the absolute value of the\nrisk difference. Since the risk difference is −0.04, its absolute value is 0.04, and\n0.04-1 = 25: thus, we would have to treat 25 untreated people to prevent one MI\nover 5 years (note the inclusion of the time period in the interpretation, much\nlike the risk difference itself requires). Convention is often that we round the\nNNT up to the nearest integer because we cannot intervene on a portion of a\nperson. However, this approach is also considered conservative.\nIn this case, the treatment was protective; when a treatment or exposure is\nharmful, we can calculate a number in the same way but often describe that value\nas a number needed to harm (NNH). However, NNT versus NNH distinctions are\nultimately a matter of both subject matter convention and clarity in explanation.\nOne key caveat to the NNT is that it can be calculated whenever a risk difference is available—calculated, but not always interpreted. If there is no obvious\n“treatment” for the exposure under study—or the treatment is vague or ambiguously defined—then presentation of the NNT may be contraindicated (though we might still want to calculate a “number needed to expose” or other analogous\nmeasure, depending on the circumstances. We discuss this further in Chapter 9.\n\n\n8.4.6.3 Population Attributable Effects\nLet’s return to an example from Chapter 2, that of the environmental contaminant (e.g., a chemical spill): suppose we were interested not in the difference in\nrisk, but in prevention. Suppose we are considering what impact it would have if\nwe had been able to prevent the contaminant from affecting anyone, such that all\nthose who were exposed were instead not exposed. As with the NNT, this idea is\ninherently causal: it imagines a world in which we can intervene to remove the\nharmful exposure and estimate the effect of doing so from the data in front of us\n(as in this chapter).\nRecall that in our initial example (Table 2.2) we stated that we enrolled 2,000\nparticipants into our study, 1,000 of whom were exposed and 1,000 of whom\nwere unexposed. The 5-year risk difference can still be calculated here as 0.04 or\n4%. But the risk difference does not answer our question, which was “what impact would it have if we could move all those in the exposed category to have the\nrisk profile of the unexposed category?” Unlike the risk difference, this is about\ncomparing the overall risk in this population (calculated in the “Total” row as\n0.050) to the overall risk in this population if the 1,000 exposed individuals had\nnot been exposed.\nHad, counter-to-fact, the 1,000 exposed individuals not been exposed, what\nwould their risk be? If we assume exchangeability between the exposed and unexposed individuals here (which might be reasonable if the exposure was essentially\ndistributed at random in the affected population), then the exposed individuals,\nhad they not been exposed, could be assumed to have experienced the same\nrisk as those who were not exposed in fact: that risk being 0.030. Thus, if all the\noriginally exposed and originally unexposed people experienced a risk of 0.030\n(Table 3.6), then the total population risk would be 0.030. We could then contrast\nthe original total population risk (0.050) to the total population risk if all exposed\nparticipants had instead been unexposed (0.030).\nBroadly, such a comparison is called a population attributable effect; the most\ncommon of such effects is the population attributable fraction (PAF). The PAF\nis generally defined as the percentage of outcomes which can be attributed to\nthe exposure—and thus, the percentage of outcomes which would disappear if,\ncounter to fact, the exposure had not occurred or was removed entirely. In this\ncase, it is calculated as the difference between the risk in the original total population and the risk in the population in which everyone is unexposed (0.050 −\n0.030), divided by the total risk in the original population (0.050): this comes out\nto 0.40. That is, 40% of the total outcome risk could be removed if we could have\nprevented exposure in all those exposed. Alternatively, we can calculate the PAF\nfrom the risk ratio (RR) and exposure prevalence (Pr(E = 1)):\nPr E RR\nPr E RR\n( ) = × − ( )\n( ) = × − ( )+\n1 1\n1 1 1\nIn this case, Pr(E = 1) is 0.5, and RR = 2.33, and so this equation becomes (0.5 ×\n(2.33 − 1)) / (0.5 × (2.33 − 1) + 1) = 0.6667/1.6667 = 0.40, the same answer as we\nestimated immediately above. As this equation implies, we should expect the PAF\nto change with the prevalence of exposure. You might wish to create a numerical\nexample exploring this phenomenon using a spreadsheet.\nWe can also calculate a population attributable risk difference, which is simply\nthe numerator above: 0.050 − 0.030 = 0.020. This is the absolute difference in risk\nwe would see over five years in the whole population if we had prevented exposure\nin all those exposed. These uses of “population attributable” correspond to what\nGreenland and Robins previously called “excess” cases of disease (Greenland &\nRobins, 1988; Rockhill, Newman, & Weinberg, 1998). As these authors note, we\nhave omitted consideration of those for whom the absence of the exposure would\nhave moved the incidence of the outcomes later in time and yet still within the\nfollow-up period (within 5 years, in our preceding example).\nAs with the NNT, a population attributable effect (and our descriptions of it) is\ninherently causal: one cannot, in a reasonable use of language, “attribute” an outcome to something which did not cause that outcome. In light of some differences\nin terminology, what seems most critical for a user of these methods is to be clear\nthat they are being used to estimate a causal effect. Then the user can be precise as\nto what causal effect they believe their calculation to be estimating, with attention\nto the causal identification conditions as well as possible additional considerations\n(see Chapter 9).\nOne final caution on PAFs is that—because many outcomes are caused by more\nthan one factor (see Section 3.7.2)—PAFs can sum to more than 1 for the same\noutcome. As a trivial example, no one can die of AIDS without having HIV infection; thus, by definition, the PAF for the exposure of HIV and the outcome\nof death from AIDS is 100%. But because people die with AIDS for all sorts of\nadditional reasons as well—having HIV is necessary but not sufficient to die of\nAIDS—the PAFs for HIV infection and (for example) tuberculosis infection will\nsum to more than 1.\n\n\n\n8.4.7 OTHER MODELS OF CAUSALITY AND CAUSAL INFERENCE\nIn this text, we focus on potential outcomes and causal DAGs as approaches to\ncausal effect estimation. However, historically, numerous other approaches have\nbeen taken to causal inference and causal effect estimation. Here, we briefly describe a few of these.\n\n8.4.7.1 The Hill Lecture\nPerhaps the most famous of these are the “causal criteria” of Sir Austin Bradford\nHill. A lecture given by Hill, the summary of which was published in Proceedings\nof the Royal Society of Medicine in 1965, described nine criteria that might help\nus distinguish whether a particular factor is a cause of disease (Hill, 1965). He\nlisted the following guideposts: strength of association, consistency of association\n(which he meant in a broad sense, not the narrow causal identification condition\nnoted earlier), specificity of association, temporality, biological gradient (such as\na dose–response relationship), plausibility, coherence (with known facts), experiment, and analogy.\nNotably, these guideposts have been repeatedly used as a checklist to determine\nwhether an association is causal, despite Hill’s specific caution that he did not\nbelieve:\nWe can usefully lay down some hard-and-fast rules of evidence that must be\nobeyed before we accept cause and effect. None of my nine viewpoints can\nbring indisputable evidence for or against the cause-and-effect hypothesis and\nnone can be required as a sine qua non.\n(Many would argue that temporality is indeed a sine qua non!)\nAgain, we are restricting ourselves in this book to causal effect estimation,\nwhich is not the same as causal inference (Greenland, 2017): in particular, the\nlatter is a much wider field, and we do not rule out Hill’s guidelines as potentially useful for larger scale considerations of causal inference. Ultimately, Hill’s\ngoal was in deciding when sufficient evidence has accumulated to drive action to\nguard health: a decision which involves more than causal effect estimation. In this\nwork, we rely on a combination of the potential outcome framework and causal\ndiagrams to help guide causal effect estimation.\n\n\n8.4.7.2 Sufficient Component Causal Framework (“Causal Pies”)\nThis model of causality was introduced by Rothman in 1976 (1976, 2012) and is\nvery helpful in thinking about “multicausality”: the idea that events occur only\nin the presence of multiple causal factors. Specifically, a particular case of disease generally has many contributing causes, all of which are necessary to that\nparticular case. For example, person Z was eating dinner when they suddenly\nsuffered a heart attack; the restaurant called paramedics but person Z died before they could arrive. Here, perhaps the necessary causes of the outcome of death\ninclude the heart attack and also the fact that the paramedics did not arrive in\ntime (Figure 3.8). Had either of those two causes been absent (i.e., had the heart\nattack not occurred or had the paramedics arrived in time), the outcome (death)\nwould not have occurred. Alternatively, had there been a heart attack and yet a\ntimely paramedic arrival—or no heart attack, but a late paramedic arrival—then\nperson Z would not have died. (It is, of course, notable that without the heart\nattack, a paramedic arrival would have been very strange—but nonetheless Z\nwould still be alive.)\nIn this framework, each instance of the outcome gets its own pie, reflecting the\ncauses that were necessary to that case of the outcome: so a different death might\nbe attributed to heart attack and lack of a phone so that the paramedics could not\nbe called in the first place, and a third death to other factors entirely. Though we\nwill not dwell on causal pies further, it is worth mentioning that the causal types\nwe introduced earlier (doomed, immune, etc.) can be mapped to people who do\nor do not have certain component causes.\n\n\n\n8.4.8 SUMMARY\nThere is contentious and ongoing debate about the best approach to causal effect\nestimation and causal inference within epidemiology. We ally ourselves with the\nview that both potential outcomes and causal diagrams are extremely useful in\nthe conceptualization and estimation of quantitative causal effects: that is, in the\nestimation of the quantitative effect of a well-defined exposure on an outcome.\nThis is the approach we take in this work because our goal—improving the health\nof populations—requires well-defined exposures and outcomes and estimates of\nthe causal effects of interventions against those exposures. We do not make any\nuniversal claim about the applicability of this framework to causality or causal inference in general—only the estimation of quantitative causal effects.\nThe view of causality presented here, including potential outcomes and causal\ndiagrams, integrated with an understanding of descriptive and predictive epidemiology (in the form of surveillance and screening, Chapter 4), key study designs (Chapters 5–8), and the causal impact framework (Chapter 9), is the best\nway I know to help craft (relatively!) unambiguous epidemiologic inquiries, the\nanswers to which have high potential to improve public health.\n(Glass et al. 2013)\n\nGlass, Thomas A, Steven N Goodman, Miguel A Hernán, and Jonathan M Samet. 2013. “Causal Inference in Public Health.” Annual Review of Public Health 34 (January): 61–75. https://doi.org/10.1146/annurev-publhealth-031811-124606.\nSuy diễn nhân quả có vai trò trung tâm trong y tế công cộng. Việc xác định một mối quan hệ có phải là nhân quả hay không cho thấy khả năng thực hiện một biện pháp can thiệp.\nTổng hợp các hướng dẫn lâu đời nhằm phiên giải chứng cứ như một sự ủng hộ cho quan hệ nhân quả và so sánh với nền tảng kết cuộc khả dĩ vốn khuyến khích cách suy nghĩ rằng nguyên nhân là các biện pháp can thiệp. Trong y tế công cộng, nền tảng này là phù hợp hơn và cung cấp ước tính về những hệ quả của hành động so với cách định nghĩa kém chính xác về tác động nhân quả của yếu tố nguy cơ. Nhiều phương pháp thống kê hiện đại đã vận dụng cách tiếp cận này. Khi một biện pháp can thiệp không thể được xác định, quan hệ nhân quả vẫn có thể tồn tại, nhưng cách thức can thiệp để thay đổi kết cuộc sẽ không còn rõ ràng nữa. Về ứng dụng, chúng ta cần ghi nhận cấu trúc phức tạp của các quá trình nhân quả và thu thập dữ liệu phù hợp để nghiên cứu chúng. Các phương pháp tiếp cận mới này cần được vận dụng để giải quyết những thách thức ngày càng phức tạp về y tế công cộng trong thế giới toàn cầu hoá của chúng ta."
  },
  {
    "objectID": "epibasic_08_causal_inference.html#mở-đầu",
    "href": "epibasic_08_causal_inference.html#mở-đầu",
    "title": "8  Suy diễn nhân quả",
    "section": "8.5 Mở đầu",
    "text": "8.5 Mở đầu\n\n8.5.1 Tổng quan\nViệc xác định liệu một mối quan hệ có phải là nhân quả hay không có thể mang lại những hệ quả quan trọng về y tế công cộng, gợi ý cho nhu cầu hoặc ít nhất là khả năng thực hiện một hành động nhằm giảm phơi nhiễm với một chất độc hại hoặc gia tăng phơi nhiễm với một yếu tố có lợi. Vì vậy, suy diễn nhân quả thường được gắn kết vào thực hành y tế công cộng và xây dựng chính sách một cách trực tiếp hoặc gián tiếp. Nhân viên y tế quyết định về một can thiệp dựa trên hệ quả gây ra bởi một quan hệ nhân quả mặc định nào đó. Suy diễn nhân quả được kết hợp vào các quá trình pháp lý, ví dụ như quyết định của Tổ chức Bảo vệ Môi trường Hoa Kỳ (EPA) đối với chất gây ô nhiễm không khí ngoài trời chính và các hoá chất độc hại, và của Văn phòng Cựu chiến binh nhằm bồi thường cho cựu binh Mỹ về những tình trạng hay bệnh lý liên quan đến công vụ. Bằng chứng về y tế công cộng\nThe determination that an association is causal can have profound public health consequences, signaling the need or at least the possibility to take an action to reduce exposure to a hazardous agent or to increase exposure to a beneficial one. Consequently, causal inference is implicitly and sometimes explicitly embedded in public health practice and policy formulation. Practitioners decide on interventions on the basis of consequences produced by a presumed causal relationship. Causal inference is embedded in regulatory processes, for example those of the US Environmental Protection Agency (EPA) with regard to major outdoor air pollutants and the hazards of chemicals, and those of the Department of Veterans Affairs, in compensation of US veterans for service-connected conditions and diseases [Agent Orange Act, Pub. L. 102-4 (1991); Clean Air Act 42 U.S.C. § 7401-7671q (2008); 36, 37]. Public health evidence may be prominent in legal proceedings in which judgment about the existence of a causal relationship is pivotal in determining guilt and liability for damages (16, 72). Causal inference is also embedded in many aspects of medical practice through the principles of evidence-based medicine, where decisions about harms or benefits of therapeutic agents are based, in part, on rules for how to measure the strength of evidence for causal connections between interventions and health outcomes (20).\nThe history of public health and of its quantitative disciplines, epidemiology and biostatistics, can be seen as one long discourse on disease causation, the ultimate targets of which are to find and to mitigate reversible causes (22, 23, 33, 46, 50, 67). Over that history, a variety of \"frameworks\" for thinking about causation have risen to coincide with the dominant problems of the day and the scientific understanding of their etiology. During the ravages of the cholera epidemics of the nineteenth century, John Snow gathered evidence in support of waterborne transmission, using what Frost later called his ordered \"chains of inference\" (11, p. IX) (15, 73, 74). With the advent of germ theory, Koch’s postulates provided a more systematic and formalized approach that worked well within the specificity of unique germ-disease links (8).\nIn the 1950s and 1960s, what we call the classic framework for causal thinking was articulated by Sir Austin Bradford Hill, who added to this discourse with his causal criteria against the backdrop of international debate about the causal role of smoking in the epidemic of lung cancer (53, 76). This classic framework was developed to identify the causes of diseases and particularly to determine the role of smoking in lung cancer (33, 71), but its use has been extended to public health decision making, a domain where questions about causal effects relate to the consequences of interventions that have often been motivated by the identification of causal factors. This framework, described below, has proven useful and has driven decision making in public health for decades. However, the framework does not reflect the current, more clearly articulated view of causal processes. Additionally, the guidelines used to evaluate evidence have not changed for decades, even as the causal questions have become more complex, beyond the original intent of this framework.\nOne important limitation of the classic view of disease causation arising from the Hill criteria has been the lack of a formal basis for evaluating causal hypotheses. Only in the past several decades have investigators explored more formally the foundational mathematical and conceptual issues required for rigorous estimation of causal effects, particularly in circumstances where randomization of treatment assignment that insures exchangeable comparison groups is unfeasible. Since 1970, the frequency and intensity of formal discourse on causation and causal inference have increased, and the field has progressed toward what we term the modern approach, based on the counterfactual or potential outcomes framework (18, 25).\nIn this review, we first describe and comment on the classic framework that is generally attributed to Sir Austin Bradford Hill and the advisory committee that prepared the 1964 US Surgeon General’s report on smoking (33, 71). We follow with a brief review of the modern framework based on the counterfactual, or potential, outcomes model for estimating causal effects. The latter approaches are unified by an analytic effort to approximate the experimental paradigm that balances treated (exposed) and untreated (unexposed) groups on other factors. We next carry this counterfactual approach to the broad and multilevel nature of causal questions, as formulated over the past several decades, and consider causal inference in the context of such questions and their implications for public health actions (14). We end with consideration of how these new approaches—broader frameworks for formulating causal questions and developing analytical tools to answer them—can be used to reduce uncertainty associated with causal determinations. The interplay between strength of evidence and remaining uncertainties typically figures prominently in decision making. More pragmatically grounded and transparent approaches are needed as we face such challenges as the rise of obesity throughout the world—an example that necessitates a multilevel framing of underlying causal processes, with structures extending from the genes of individuals to the foods sold worldwide by multinational corporations, as the basis for formulating interventions (35). This type of framework has already proven valuable in approaching tobacco control (Figure 1). The upstream drivers of the epidemic are clear at this point in its course: a large and powerful global industry led by a handful of powerful multinational corporations. The role of factors at other levels has also been characterized: cultural acceptance of smoking, laws, peers, and the family. Now, we are probing the genetic basis of susceptibility to nicotine addiction and tobacco-caused diseases. Within the modern framework, such structure leads to questions and counterfactuals at multiple levels: At the highest level, what would be the disease burden, absent the upstream factor (e.g., the tobacco industry), and at the lowest level, what would be the disease risk for genetically susceptible individuals, absent the environmental factor (e.g., smoking)? The structure also raises the possibility of interventions at multiple levels, reflecting how interventions might be carried out in practice.\n\n\n8.5.2 Một vòng khái quát về triết học\nAlthough public health scientists and practitioners have disagreed fiercely at times about what is required of causal explanations, the idea that causal relationships can be proven has rarely been seriously questioned. But in the long and contentious discourse on causation in philosophy (3), one can discern two distinct classes of causation theory. On one side are the descendants of Locke and John Stuart Mill, who argued that causation can be verified through the careful implementation of the scientific method and the power of experimentation. On the other side is a parallel line of discourse that extends from David Hume, who argued that even though nature may contain real causal \"connexions\" between phenomena, causation cannot be empirically verified (36). This skeptical tradition had no better spokesman than Bertrand Russell (64), who in a famous essay delivered to the Aristotelian Society of 1912, wrote, \"The law of causality, I believe, like much that passes muster among philosophers, is a relic of a bygone age, surviving, like the monarchy, only because it is erroneously supposed to do no harm\" (p. 1).\nAlthough the science of epidemiology and the practice of public health fall clearly into the pragmatic tradition of Locke and Mill, evidence of the influence of Hume and Russell can be found in the early skepticism of R.A. Fisher (9) and Karl Pearson, the father of modern statistics, who argued that the correlation between two variables, once known, is all there is to know, a view that persists with some epidemiologists. In their review of causal inference in epidemiology, Lipton & Ødegaard (47) ask what is really added to the statement that smokers are at X-fold increased risk of lung cancer by the statement that smoking is a cause. From a policy point of view, the use of causal language has obvious advantages, and it has been widely embraced not only by researchers but by policy makers. The legacy of Hume and Russell urges us to be cautious because assigning causal significance to some phenomena also provides an easy target for skeptics and, potentially, affected stakeholders to derail reasonable interventions on the basis of an absence of proof. Public health practitioners and researchers are interested primarily in effecting change and not in engaging in philosophical debates, but the ghost of Russell reminds us that the invocation of causal language has powerful consequences, both good and bad.\nThe challenge of determining causation in public health has always been shaped by the limitations of the available data, the understanding of the underlying biological or sociological processes, and our ability to intervene in the real world. Faced with sometimes limited data and an often poor understanding of a network of connected factors in a complex world, we revert to pragmatism. Public health science seeks the certainty of the experiment as its organizing principle. Holland (34) says it succinctly in a famous paper, \"Put as bluntly and as contentiously as possible, in this article I take the position that causes are only those things that could, in principle, be treatments in experiments\" (p. 954).\nThis statement is formalized in the potential outcomes framework, which compares what is observed to what might have been observed, all other things being equal, under a counterfactual scenario. The potential outcomes framework is a powerful tool that has implications for how we see the world and to determine what types of questions can be answered in a useful way for public health purposes and what kinds of questions are beyond our capacity to answer (25, 55, 61, 62, 63).\n\n\n8.5.3 Các cách tiếp cận về suy diễn nhân quả trong y tế công cộng\nThe classic approach to causal inference in public health, described quite similarly across textbooks and widely used in practice, has its roots in the seminal debate around smoking as a cause of lung cancer in the 1950s and 1960s (33, 71). At that time, the results of epidemiological studies had shown associations of smoking with increased risk for lung cancer and other cancers, for coronary heart disease, and for \"emphysema\" and \"bronchitis.\" The most relevant data came from case-control and cohort studies and findings from animal models and lab studies characterizing the components of tobacco smoke. Rising mortality rates from lung cancer and coronary heart disease provided a strong imperative for taking action to reduce cigarette smoking. However, taking action required that smoking be established as the cause of the increases in mortality. Even as the epidemiological evidence mounted, the tobacco industry implemented a wide-ranging strategy to question the credibility of epidemiological evidence generally and of the most pivotal studies specifically (54). This tactic of creating doubt about the evidence heightened tension around the challenge of interpreting the findings of epidemiological research, and its use attests to the societal importance of causal determinations. The manufacture and dissemination of doubt remain strategies today, widely used by stakeholders whose interests are potentially threatened by a causal finding (49).\nThe framework that was put forth for causal inference in the 1960s involved expert judgment grounded in a set of guidelines or criteria (Table 1). The long-standing discussion among philosophers was acknowledged as these guidelines were elaborated, but the need for a pragmatic and timely approach foreshortened debate. The framework was effective for smoking and lung cancer, one of its first applications. Smoking is a potent cause, increasing the risk of lung cancer about 20-fold and leading to most cases of lung cancer; consequently, the evidence from observational studies was consistent and strong, and temporality was clear. As described by their originators and as used in practice, these criteria (or what Hill calls \"viewpoints\") are not absolute nor does inference of a causal relationship require that all criteria be met. In fact, only temporality is requisite. Some features of evidence, most notably specificity, have proven to have little applicability for noncommunicable diseases that have multiple causes. The classic approach is vulnerable to subjectivity in the evaluation of evidence and to manipulation of the evidence, and stakeholders potentially affected by the finding that an association is or is not causal may take opposing positions on evidence interpretation. Additionally, as constructed and applied, the framework assumes a simplistic direct relationship between cause and putative effect without explicit consideration of the structure of the underlying causal processes. For example, tobacco smoking is an indisputable cause of lung cancer, but more distally in the causal process, a small number of multinational tobacco companies produce most of the cigarettes sold and smoked worldwide (Figure 1). The inference about cause became the rationale for intervention, but the causal conclusions were not couched in the consequences of specific actions to reduce or eliminate cigarette smoking. And later, public health action was aimed at the individual smoker, rather than at the upstream system of cigarette manufacture, advertising, and distribution. This limited focus is a key characteristic of the traditional approach; causal determinations were made by epidemiologists and others in public health about various risk factors without considering the effect of a specific way of changing them.\nToday, public health practice can be seen to be influenced by both the classic and modern frameworks, as exemplified in the following case studies. In setting outdoor air quality standards in the United States, causal inference and associated counterfactuals figure in the decision process. Two sections of the US Clean Air Act (108 and 109) address the major outdoor air pollutants, requiring the Administrator of the EPA to set National Ambient Air Quality Standards (NAAQS) such that \"the attainment and maintenance of which in the judgment of the Administrator, based on such criteria and allowing an adequate margin of safety, are requisite to protect the public health\" (p. 5697). The phrase \"such criteria\" refers to the accumulated evidence on harm, giving emphasis to that reported since the last review of the NAAQS. The present process for a pollutant, e.g., ozone, begins with a review of the evidence, assembled in the Integrative Science Assessment (Figure 2). The process for causal inference draws on the long-standing classic approach and classifies the strength of evidence in a five-level scheme (\"not likely,\" \"inadequate,\" \"suggestive,\" \"likely,\" and \"causal\"). The classification, in part, determines the effects that are subsequently considered in the risk analysis, which estimates the pollutant-related burden of disease and the consequences of potential changes to the NAAQS. Those effects for which the evidence reaches the level of \"likely\" or \"causal\" are generally advanced for consideration in the risk analysis and consequently figure in the policy judgment made by the Administrator on revising the NAAQS for a pollutant. The risk analysis models the counterfactual distribution of health outcomes under different scenarios of pollution reduction and under no intervention. The risk analysis has the modern approach as its conceptual underpinning.\nThe International Agency for Research on Cancer (IARC) of the World Health Organization operates its Monograph Program, which conducts systematic reviews to classify agents by their carcinogenicity (39). The general approach involves a meeting of a multidisciplinary working group that reviews evidence relevant to a particular agent in four broad categories: (a) exposure, (b) studies of cancer in humans, (c) studies of cancer in experimental animals, and (d) mechanistic and other relevant data. The human and animal evidence is separately considered, and for each category, the strength of evidence for causation is classified in a four-level hierarchical schema: sufficient, limited, inadequate, or suggesting lack of carcinogenicity. The evidence is evaluated with an approach based in the Hill or classic criteria. Evidence for the role of particular mechanisms is evaluated as \"weak,\" \"moderate,\" or \"strong,\" and investigators consider the relevance of the mechanism to cancer in humans. The overall classification is based primarily on the animal and human findings (Figure 3), but the mechanistic evidence can figure in the classification as well. This approach, for example, resulted in the 2011 classification of radiofrequency electromagnetic radiation, the type emitted by mobile phones, as a possible human carcinogen, Group 2B in the IARC schema (2)."
  },
  {
    "objectID": "epibasic_08_causal_inference.html#tiếp-cận-suy-diễn-nhân-quả-bằng-cách-so-sánh-kết-cuộc-của-các-biện-pháp-can-thiệp-y-tế-công-cộng-khác-nhau",
    "href": "epibasic_08_causal_inference.html#tiếp-cận-suy-diễn-nhân-quả-bằng-cách-so-sánh-kết-cuộc-của-các-biện-pháp-can-thiệp-y-tế-công-cộng-khác-nhau",
    "title": "8  Suy diễn nhân quả",
    "section": "8.6 Tiếp cận suy diễn nhân quả bằng cách so sánh kết cuộc của các biện pháp can thiệp y tế công cộng khác nhau",
    "text": "8.6 Tiếp cận suy diễn nhân quả bằng cách so sánh kết cuộc của các biện pháp can thiệp y tế công cộng khác nhau\nAs described above, a key role for causal inference in public health is the comparison of the distribution of health outcomes after different interventions. In an ideal world, these comparisons would be conducted via randomized experiments, and all public health decisions would be based on the findings of those experiments. For example, the integration of smoking-cessation programs into the health care system would ideally rely on the findings from long-term randomized studies comparing the efficacy of the intervention in large groups of people from the target population that adhered to the intervention with control groups. Similarly, the decision to increase taxation or regulation of tobacco products would be based in studies that randomly allocated these policies across communities or counties. Unfortunately, such randomized experiments are often unethical, impractical, or simply too lengthy for timely decision making. As a result, causal inferences for public health are usually derived from observational studies, buttressed by other lines of evidence if available.\nThe use of observational, rather than experimental, data for causal inference in public health raises several concerns. One particularly relevant concern for public health is that the interventions under consideration may be vaguely defined, if at all, limiting the relevance of the findings for public health decision making. For example, the comparison of observed mortality rates between obese and lean people suggests a possible causal relation between obesity and death but offers little guidance for action: Should solutions be found in exercise programs in the workplace, reduction of sizes of sugared sodas available in retail stores, liposuction (26, 32)? Although obesity may meet criteria for a causal factor in the classic framework, the association between obesity and mortality offers little insight for preventive action. One alternative is to focus on the contrast between individuals randomly assigned to dietary modification versus those who are not or a contrast between communities randomized to taxation of sugary drinks versus those who are not. The findings from such experiments would provide direct, actionable information about the effects of interventions against obesity. The observational study that compares obese and lean people provides only indirect evidence and lacks a formally testable causal relation in the absence of further specification.\nOne way to address this concern and bridge the gap between the observational data and public health decision making is to design observational analyses in such a way that the observational data emulate those from hypothetical randomized experiments with relatively well-defined interventions. For example, observational data could be used to mimic a hypothetical randomized experiment involving dietary interventions by comparing the observed outcomes of individuals who change versus those who do not change their diet during the study period; or data could be used to mimic a hypothetical randomized experiment of food policy by comparing health outcomes between schools that did and did not restrict access to sugary drinks. This approach is built into the counterfactual or potential outcomes framework proposed by Neyman (51), expanded by Rubin (61, 62), and generalized to time-varying exposures by Robins (55, 56). A counterfactual approach to causal inference in public health requires that the causal effects are defined in terms of contrasts between the distributions of the health outcomes under different (hypothetical) well-defined interventions.\nComparing relatively well-defined public health interventions is only the first problem for causal inference from observational data, however. Even well-defined intervention groups will not usually be directly comparable because the key characteristics of individuals in each group are likely to differ. For example, individuals who change their diet may also adopt a healthier lifestyle than those who do not, and schools that change their food policies may serve populations with less economic inequality than do those schools whose policies remain unchanged. This noncomparability problem, commonly referred to as confounding, is a fundamental problem for causal inference using observational data.\nThe most common approach to mitigate confounding is to measure as many variables as possible that are responsible for the noncomparability and to adjust for them in the statistical analysis. The available methods to adjust for measured confounders are stratification, matching, standardization, inverse probability weighting, and g-estimation. In practical applications with sparse or high-dimensional data, these adjustment methods are implemented with the help of statistical models. For example, adjustment via stratification is often carried out using conventional regression models.\nSometimes the measured confounders are used to estimate each study participant’s probability of receiving the exposure of interest. For binary exposures (e.g., yes/no), this probability is referred to as the propensity score (60). If the propensity score is available for adjustment, then the individual variables are not necessary. Inverse probability weighting and g-estimation are methods based on propensity scores. Propensity scores can also be used to adjust for confounding via stratification (e.g., by adding the propensity score as a covariate in the regression model), matching, and standard-ization.\nFor the above methods to provide valid causal inferences, all the confounders must have been identified and appropriately measured, a condition that is not empirically testable. One alternative method to eliminate confounding from the effect estimate is instrumental variable estimation (17, 31). Unlike the other methods, instrumental variable estimation does not require investigators to measure any confounders. Rather, it requires them to identify and appropriately measure an instrument, which is roughly defined as a variable that has an effect on the exposure and that is unassociated with the outcome except through its effect on the exposure. Unfortunately, it is impossible to verify empirically that a particular variable is an appropriate instrument. Furthermore, valid instruments can provide only lower and upper bounds for the magnitude of the causal effect of interest. Typically, these bounds are not helpful for decision making because they range from beneficial to harmful effects. As a result, most applications of instrumental variables make additional untestable assumptions to obtain point estimates for the effect of interest.\nWhen exposures are time-varying, a new potential problem arises: Perhaps the confounders (also time-varying) are themselves affected by prior exposure levels. In the presence of this exposure-confounder feedback process, some of the above methods—stratification and matching—cannot be generally used for valid causal inference. Valid adjustment for measured confounding requires the use of the parametric g-formula (a generalization of standardization) (55, 68), inverse probability of marginal structural models (27, 58), or g-estimation of nested structural models (which include some forms of instrumental variable estimation for time-varying exposures as a particular case) (28, 57). These methods, developed by Robins and collaborators since 1986, are often referred to as causal methods because they can be applied to obtain valid causal inferences, even in complex settings with time-varying confounders affected by prior exposure (29, 55).\nAnother recent addition to causal inference methodology is the use of causal diagrams (directed acyclic graphs, or DAGs). Although not a data-analysis method themselves, causal diagrams are used to represent the structure of the causal networks linking exposure, outcome, confounders, and other variables, requiring an explicit formulation of the relationships among these factors. Thus, causal diagrams are a helpful tool to detect, graphically, possible sources of bias and to guide investigators in the design of their data analysis (19, 30, 52)."
  },
  {
    "objectID": "epibasic_08_causal_inference.html#section",
    "href": "epibasic_08_causal_inference.html#section",
    "title": "8  Suy diễn nhân quả",
    "section": "8.7 ",
    "text": "8.7"
  },
  {
    "objectID": "epibasic_08_causal_inference2.html",
    "href": "epibasic_08_causal_inference2.html",
    "title": "9  Suy diễn nhân quả - Một ví dụ",
    "section": "",
    "text": "Đây là một tình huống được giả lập dựa theo Thử nghiệm Can thiệp Khuyến khích Bú sữa mẹ (Promotion of Breastfeeding Intervention Trial, PROBIT). Đây là một thử nghiệm lâm sàng, có nhóm chứng, phân nhóm ngẫu nhiên trong đó các cặp mẹ-con tại 31 bệnh viện phụ sản tại Belarus được phân ngẫu nhiên vào nhóm nhận chăm sóc thông thường hoặc nhóm được đề nghị tham gia một chương trình khuyến khích bú sữa mẹ.\nMục tiêu của nghiên cứu nhằm tìm hiểu tác động của chương trình và của sữa mẹ lên sự phát triển sau đó của trẻ.\nDữ liệu được giả lập với kết cuộc quan tâm là cân nặng của trẻ lúc 3 tháng tuổi, và tìm hiểu mối liên quan giữa kết cuộc này với phơi nhiễm được xác định lúc bắt đầu can thiệp và một số yếu tố dưới nguồn.\n\n\n\n\\(Y\\): kết cuộc\n\\(A\\): can thiệp (phơi nhiễm)\n\\(\\mathcal{A}\\): tập hợp bao gồm tất cả các giá trị của can thiệp (phơi nhiễm)\n\\(\\mathcal{a}\\): giá trị cụ thể của can thiệp (\\(\\mathcal{a} \\in \\mathcal{A}\\))\n\\(\\mathfrak{a}(\\mathcal{a})\\): hành động gán \\(A\\) là \\(\\mathcal{a}\\) (tương đương với \\(do\\) của Pearl)\n\\(f(Y|do(A=\\mathfrak{a}))\\): phân phối \\(f\\) của \\(Y\\) khi \\(A\\) được gán vào \\(\\mathcal{a}\\)\n\n\n\n\n\nĐịnh nghĩa can thiệp và các giá trị về can thiệp phù hợp với câu hỏi nghiên cứu.\nĐịnh nghĩa kết cuộc tương ứng với câu hỏi nghiên cứu.\nĐịnh nghĩa dân số quan tâm.\nThiết lập từng kết cuộc tiềm năng cho mỗi mức độ về can thiệp mà dân số nghiên cứu có thể trải qua.\nXác định tác động nhân quả đích dưới dạng các tham số (estimand) thể hiện sự tương phản giữa các phân bố kết cuộc tiềm năng.\nTrình bày các giả định kiểm chứng ước lượng về tác động nhân quả từ dữ liệu.\nƯớc tính tác động nhân quả đích.\nĐánh giá giá trị của các giả định và thực hiện phân tích độ nhạy nếu cần thiết.\n\n\n\n\n\n\nĐịnh nghĩa can thiệp phụ thuộc vào (1) bối cảnh thực hiện nghiên cứu và (2) dữ liệu hiện có.\nCan thiệp, theo nghĩa rộng, có thể bao gồm các biến số thay đổi được hoặc các biến số không thay đổi được (ví dụ các biến số về di truyền, giới tính sinh học)\nTrong nghiên cứu này, chúng ta có thể mong muốn định nghĩa tác động nhân quả của một can thiệp về bú sữa mẹ trên cân nặng của trẻ lúc 3 tháng tuổi.\nChúng ta có thể định nghĩa “can thiệp về bú sữa mẹ” theo một số cách khác nhau:\n\n\\(A_1\\): loại can thiệp được phân ngẫu nhiên (ví dụ như chương trình khuyến khích được cung cấp)\n\\(A_2\\): việc tiếp nhận can thiệp (ví dụ như bà mẹ tham gia vào chương trình khi được cung cấp, có thể bao gồm việc trao đổi với chuyên gia tư vấn về sữa mẹ, đọc tờ rơi về bú sữa mẹ)\n\\(A_3\\): việc thực hiện can thiệp đích (ví dụ như bà mẹ bắt đầu cho con bú sữa mẹ)\n\\(A_4\\): việc hoàn tất can thiệp đích (ví dụ như bà mẹ bắt đầu cho con bú sữa mẹ và duy trì trong 3 tháng)\n\nMỗi định nghĩa can thiệp trên hướng đến một loại hình bú sữa mẹ khác nhau:\n\nChuyên gia về y tế công cộng sẽ quan tâm đến định nghĩa \\(A_1\\) vì sử dụng định nghĩa này sẽ giúp đưa ra quyết định có cung cấp BEP hay không.\nNgười mẹ sẽ quan tâm đến các định nghĩa \\(A_2, A_3, A_4\\) vì các định nghĩa này sẽ giúp họ quyết định có thên tham gia vào chương trình hay không, nên bắt đầu cho con bú sữa mẹ hay không, nên duy trì việc cho con bú sữa mẹ hay không?\n\nLưu ý rằng các định nghĩa trên vẫn chưa hoàn toàn rõ ràng, ví dụ như:\n\n\\(A_4 = 0\\) : có thể bao gồm nhiều giai đoạn cho con bú sữa mẹ khác nhau (từ 0 đến dưới 3 tháng).\n\\(A_3 = 1\\): có thể bao gồm nhiều giai đoạn cho con bú sữa mẹ khác nhau sau khi đã bắt đầu cho con bú sữa mẹ.\n\nCác định nghĩa khác nhau trên thể hiện một chuỗi phơi nhiễm (exposure chain). Và can thiệp vào một giai đoạn nhất định trong chuỗi phơi nhiễm sẽ tác động đến các mức độ phơi nhiễm sau đó.\n\n\nHình sau thể hiện chuỗi phơi nhiễm được sử dụng để giả lập dữ liệu:\n\n\n\n\nTrong nghiên cứu này, kết cuộc quan tâm có thể là\n\ncân nặng của trẻ lúc 3 tháng tuổi,\nsự thay đổi cân nặng của trẻ lúc 3 tháng tuổi so với lúc mới sinh,\nliệu cân nặng của trẻ lúc 3 tháng tuổi có cao hơn một ngưỡng nhất định.\n\n\n\n\n\n\nTác động nhân quả thường phụ thuộc vào các đặc tính nền, do đó có thể có độ lớn khác nhau ở những nhóm đối tượng khác nhau. Nhà nghiên cứu có thể quan tâm nhiều hơn đến một vài nhóm đối tượng cụ thể. Do đó, cần xác định và mô tả rõ nhóm đối tượng trong dân số cần quan tâm.\nViệc xác định các nhóm đối tượng này dựa trên một số đặc tính nhất định của người tham gia nghiên cứu và sẽ dẫn đến các tác động có điều kiện (conditional effects)\nNhà nghiên cứu và người làm chính sách có thể muốn tìm hiểu xem liệu can thiệp về bú sữa mẹ có hiệu quả hơn ở những người mẹ có học vấn thấp (có nguy cơ cao sinh trẻ nhẹ cân) hay không. Ngoài ra, họ cũng có thể quan tâm đến hiệu quả can thiệp ở những người thực sự bị phơi nhiễm.\n\n\n\n\n\n\n\n\\(Y_{\\mathfrak{a}(\\mathcal{a})}\\) là kết cuộc sẽ quan sát được nếu phơi nhiễm được gán là \\(\\mathcal{a}\\) .\nỞ đây cần xem xét đến 2 giả định: (1) Không có sự can thiệp (no interference) và (2) Nhất quán về nhân quả (causal consistency)"
  },
  {
    "objectID": "epibasic_02_dis_epi.html",
    "href": "epibasic_02_dis_epi.html",
    "title": "2  Bệnh và dịch",
    "section": "",
    "text": "Tài liệu học tập này được xây dựng dựa trên Chương 2 của sách Dịch tễ học cơ bản do bộ môn Dịch tễ học (Khoa Y tế công cộng, Đại học Y Dược TP Hồ Chí Minh) mà chủ biên là PGS. TS. Nguyễn Đỗ Nguyên biên soạn.\n\n\n\nLiệt kê được bốn giai đoạn trong quá trình phát triển của một bệnh.\nLiệt kê được ba thành phần của dây chuyền lây.\nMô tả được những ứng dụng của lịch sử tự nhiên và dây chuyền lây trong lĩnh vực phòng ngừa.\nLiệt kê được các hình thức của một vụ dịch, và cách xác định một trường hợp bệnh"
  },
  {
    "objectID": "epibasic_02_dis_epi.html#bệnh-và-sự-xuất-hiện-bệnh",
    "href": "epibasic_02_dis_epi.html#bệnh-và-sự-xuất-hiện-bệnh",
    "title": "2  Bệnh và dịch",
    "section": "2.2 Bệnh và sự xuất hiện bệnh",
    "text": "2.2 Bệnh và sự xuất hiện bệnh\n\n2.2.1 Tam giác Dịch tễ học\nCó nhiều mô hình khác nhau nhằm giải thích sự xuất hiện của bệnh. Một mô hình kinh điển và đơn giản thường được sử dụng là tam giác dịch tễ học; trong đó bệnh là kết quả của sự tương tác giữa ba yếu tố tác nhân gây bệnh, túc chủ, và môi trường tạo thuận lợi cho sự phơi nhiễm.\n\n\n2.2.1.1 Tác nhân\nTrước đây, từ \"tác nhân\" ám chỉ một vi sinh vật truyền nhiễm như virus, vi trùng, ký sinh trùng, hoặc các vi sinh vật khác. Ngày nay, khái niệm về tác nhân được mở rộng ra để bao gồm những nguyên nhân vật lý và hoá học có thể gây ra bệnh đối với các bệnh lý mạn tính không lây.\n\n\n2.2.1.2 Túc chủ\nTúc chủ chỉ người có thể mắc bệnh. Có nhiều yếu tố nội tại của túc chủ ảnh hưởng đến sự tiếp xúc, tính cảm nhiễm, hoặc đáp ứng của một cá nhân đối với tác nhân gây bệnh:\n\nSự tiếp xúc với yếu tố phơi nhiễm bị ảnh hưởng bởi tuổi, chủng tộc, giới, tình trạng kinh tế xã hội, và những hành vi (thí dụ, hút thuốc lá, lạm dụng thuốc, kiểu sống, những thực hành tính dục và ngừa thai, tập quán ăn).\nTính cảm nhiễm và đáp ứng của một người đối với một tác nhân gây bệnh bị ảnh hưởng bởi thành phần di truyền, tình trạng dinh dưỡng và miễn dịch, cấu trúc cơ thể học, bệnh kèm theo hoặc thuốc đang sử dụng, và bản chất tâm lý.\n\n\n\n2.2.1.3 Môi trường\nBao gồm những yếu tố bên ngoài ảnh hưởng đến tác nhân và cơ hội tiếp xúc. Chúng bao gồm những yếu tố vật lý (địa dư, thời tiết), những yếu tố sinh học (côn trùng giúp lan truyền tác nhân); và những yếu tố kinh tế xã hội (sự đông đúc, vệ sinh, và sự sẵn có của những dịch vụ sức khoẻ).\n\n\n\n2.2.2 Định nghĩa ca bệnh\nMột định nghiã ca bệnh là một bộ những tiêu chí để xác định rằng một người là có một bệnh nào đó, hoặc một tình trạng có liên quan đến sức khoẻ. Với một định nghiã ca bệnh chuẩn chúng ta bảo đảm rằng các trường hợp đều được chẩn đoán theo một cách giống nhau, bất kể nó xảy ra ở đâu, khi nào, hoặc được ai xác định. Từ đó, chúng ta có thể so sánh số những trường hợp bệnh xảy ra vào một thời gian hoặc nơi chốn này với số xảy ra vào một thời gian và ở một nơi khác. Với một định nghiã ca bệnh chuẩn, khi tìm thấy sự khác biệt trong sự xuất hiện bệnh, chúng ta biết rằng có khả năng đó là sự khác biệt thật sự hơn là do các trường hợp đã được chẩn đoán khác nhau.\nMột định nghiã ca bệnh gồm có những tiêu chí lâm sàng và, đôi khi, những giới hạn về thời gian, nơi chốn, và người. Những tiêu chí lâm sàng thường bao gồm những thử nghiệm xác định trong phòng xét nghiệm, nếu có, hoặc nhóm những triệu chứng (những điều phàn nàn chủ quan), dấu hiệu (những phát hiện lâm sàng khách quan), và những phát hiện khác.\nMột định nghiã ca bệnh không có nghĩa giúp chúng ta xác định một cách đơn giản là có hoặc không bệnh. Tùy theo trường hợp mà chúng ta quan tâm thoả được bao nhiêu trong số những tiêu chí đặt ra mà chúng ta có thể xếp trường hợp đó vào những nhóm chẩn đoán khác nhau. Thí dụ, trong một trận dịch sởi, chúng ta có thể xếp một người có sốt và phát ban là một trường hợp nghi ngờ, có thể, hoặc xác định là sởi, tuỳ theo sự hiện diện của những bằng chứng nào có được về sởi. Trong những tình huống khác, chúng ta tạm thời xếp một trường hợp là 'nghi ngờ', hoặc 'có khả năng' cho đến khi có kết quả của phòng xét nghiệm; và tùy theo kết quả đó, chúng ta sẽ xếp lại một trường hợp hoặc là xác định hoặc là 'không phải là một trường hợp'. Giữa một trận dịch lớn của một bệnh biết rõ nguyên nhân, chúng ta có thể xếp luôn một số trường hợp là nghi ngờ hoặc có thể, vì với mỗi bệnh nhân có hình ảnh lâm sàng hoặc tiền sử tiếp xúc phù hợp (thí dụ như đậu mùa) thì tiến hành xét nghiệm là thừa hoặc không cần thiết. Những định nghiã trường hợp không chỉ nên dựa vào kết quả nuôi cấy phòng xét nghiệm, vì đôi khi sinh vật có hiện diện nhưng không gây bệnh.\nNhững định nghiã ca bệnh có thể được thay đổi theo mục đích. Thí dụ, những nhân viên y tế cần biết càng sớm càng tốt nếu có ai đó có những triệu chứng của dịch hạch, hoặc bệnh nhiễm độc tố do thức ăn để có thể lập kế hoạch cho những hành động cần làm. Đối với những bệnh lây hiếm nhưng nghiêm trọng, khi cần phải xác định mọi trường hợp có thể, những nhân viên y tế dùng một định nghiã trường hợp lỏng lẻo, hoặc có độ nhạy cao. Ngược lại, những nhà giám sát nguyên nhân của một trận dịch lại muốn chắc chắn rằng bất cứ ai được bao gồm trong sự giám sát là thật sự có bệnh, do đó, một định nghiã trường hợp chặt chẽ, hoặc có độ đặc hiệu cao sẽ được chuộng hơn. Thí dụ, trong một trận dịch của Salmonella agona, những nhà giám sát sẽ có nhiều khả năng để xác định nguồn lây nếu họ chỉ bao gồm những người được xác nhận đã bị nhiễm khuẩn. Điều này sẽ cung cấp những thông tin giá trị hơn là bao gồm bất cứ ai có tiêu chảy cấp, vì một số người có thể đã bị tiêu chảy vì nguyên nhân khác. Điều bất lợi duy nhất của một định nghiã ca bệnh chặt chẽ là đưa đến một ước lượng non (ước lượng thấp hơn thực tế)."
  },
  {
    "objectID": "epibasic_02_dis_epi.html#lịch-sử-tự-nhiên-của-bệnh",
    "href": "epibasic_02_dis_epi.html#lịch-sử-tự-nhiên-của-bệnh",
    "title": "2  Bệnh và dịch",
    "section": "2.3 Lịch sử tự nhiên của bệnh",
    "text": "2.3 Lịch sử tự nhiên của bệnh\n\n2.3.1 Lịch sử tự nhiên của bệnh\nLịch sử tự nhiên của bệnh là quá trình diễn tiến của một bệnh trên một cá nhân theo thời gian mà không có bất kỳ một sự can thiệp nào của y khoa. Quá trình này bắt đầu với sự tiếp xúc, hoặc tích tụ những yếu tố có khả năng gây bệnh, và nếu không có can thiệp y khoa, quá trình này sẽ kết thúc bằng sự bình phục, tàn phế, hoặc chết của người bệnh. Hầu hết các bệnh đều có một lịch sử tự nhiên đặc trưng, nhưng vẫn còn những bệnh mà diễn tiến của chúng chưa được hiểu rõ. Trên một cá nhân, diễn tiến thông thường của bệnh có thể bị tạm ngưng ở bất cứ thời điểm nào khi có sự can thiệp của một biện pháp điều trị, hoặc phòng ngừa, hoặc những thay đổi của túc chủ, và rất nhiều những ảnh hưởng khác.\n\nThông thường lịch sử tự nhiên của một bệnh bao gồm các giai đoạn sau:\n\n2.3.1.1 Giai đoạn cảm nhiễm:\nLà giai đoạn mà tác nhân gây bệnh tiếp xúc hoặc tích tụ trong một túc chủ cảm thụ, đến một mức đủ để bắt đầu quá trình bệnh. Ví dụ như:\n\nBệnh mạch vành: giai đoạn mà thời kỳ nồng độ cholesterol tăng cao dần trong huyết thanh.\nBệnh lây: giai đoạn tiếp xúc với tác nhân gây bệnh (thường là một vi sinh vật).\nBệnh ung thư: giai đoạn tiếp xúc và tích tụ những yếu tố sinh ung như những sợi abestos hoặc những thành phần trong khói thuốc lá (đối với ung thư phổi), và những yếu tố kích ung, như estrogen (đối với ung thư nội mạc tử cung).\n\nNhững tác nhân gây bệnh hoặc những yếu tố tạo sự thuận lợi cho sự xuất hiện của bệnh được gọi chung là những yếu tố nguy cơ. Trong đó có những yếu tố có thể thay đổi được, thí dụ, hút thuốc lá là một hành vi nguy cơ có thể bỏ được. Tuy nhiên, một số yếu tố nguy cơ khác là không thể thay đổi, như, tuổi và giới tính được xác định là những yếu tố có thể tăng nguy cơ mắc một số bệnh.\n\n\n2.3.1.2 Giai đoạn bệnh bán lâm sàng\nLà giai đoạn bệnh lý tiềm ẩn thường theo sau sự tiếp xúc, và kết thúc khi những triệu chứng bệnh bắt đầu. Trong giai đoạn này bệnh chưa có những triệu chứng lâm sàng, nhưng tác nhân gây bệnh đã tạo ra những biến đổi bệnh lý trong cơ thể túc chủ. Ví dụ:\n\nHiện tượng xơ vữa ở động mạch vành xảy ra trước khi có những triệu chứng hoặc dấu hiệu lâm sàng của bệnh mạch vành tim\nNhững biến đổi tiền ác tính (đôi khi có thể đã là ác tính) ở mô trong các bệnh ung thư.\n\nĐối với những bệnh lây, thời kỳ này được gọi là thời kỳ ủ bệnh; đối với những bệnh mạn tính, thời kỳ này được gọi là thời kỳ tiềm ẩn. Thời kỳ này có thể ngắn khoảng vài giây trong những hiện tượng mẫn cảm, hoặc phản ứng với độc tố; cho tới khoảng nhiều thập niên đối với một vài bệnh mạn tính. Thời kỳ ủ bệnh là một thời khoảng cụ thể cho từng bệnh, thí dụ, đối với viêm gan A, thời gian này là từ 2 đến 6 tuần. Đối với bệnh bạch cầu liên quan đến tiếp xúc với nổ bom nguyên tử ở Hiroshima, đa số các trường hợp đã có thời kỳ tiềm ẩn là 6-7 năm, và biến thiên trong khoảng từ 2 đến 12 năm.\nDù rằng bệnh là tiềm ẩn trong thời kỳ ủ bệnh, nhưng vẫn có thể có một vài biến đổi bệnh lý có thể phát hiện được bằng những phương pháp xét nghiệm. Hầu hết những chương trình sàng lọc cố gắng phát hiện bệnh trong giai đoạn này của lịch sử tự nhiên, vì nếu chẩn đoán được bệnh thì can thiệp sớm có thể hiệu quả hơn là điều trị vào một giai đoạn trễ.\n\n\n2.3.1.3 Giai đoạn bệnh lâm sàng\nSự khởi phát của những triệu chứng đánh dấu sự chuyển tiếp từ bệnh bán lâm sàng sang lâm sàng, và hầu hết bệnh thường được chẩn đoán trong giai đoạn bệnh lâm sàng. Ở giai đoạn này, những biến đổi về giải phẫu và chức năng đã đủ để tạo ra những triệu chứng hoặc dấu hiệu thấy được. Diễn tiến của giai đoạn bệnh lâm sàng rất thay đổi: ở một số người, quá trình bệnh có thể không bao giờ diễn tiến đến bệnh có biểu hiện lâm sàng; tuy nhiên, ở một số người khác, nó có thể kết thúc bằng nhiều thể lâm sàng khác nhau, từ nhẹ đến nặng, hoặc tử vong.\n\n\n2.3.1.4 Giai đoạn hồi phục, tàn phế, hoặc chết\nSau khi qua hết giai đoạn lâm sàng, bệnh sẽ bước sang giai đoạn hồi phục, tàn phế, hoặc chết. Sự tàn phế được hiểu như là sự hạn chế hoạt động của một cá nhân, và thường chỉ sự mất chức năng hơn là những khiếm khuyết thể chất. Cùng một mức độ tàn phế về thể chất như nhau nhưng mỗi cá nhân sẽ có phản ứng khác nhau, do đó, chức năng của cơ quan hay bộ phận đã bị tàn phế sẽ biểu hiện khác nhau.\n\n\n\n2.3.2 Những ứng dụng của lịch sử tự nhiên của bệnh\n\n2.3.2.1 Phòng ngừa\n\nHiểu biết về lịch sử tự nhiên của một bệnh cho thấy bệnh có một quá trình diễn tiến theo thời gian, và một khi bệnh đã xuất hiện thì thường những thay đổi bệnh lý do nó tạo ra là không thể thay đổi được. Do đó, mục đích của y khoa là, nếu có thể được, luôn luôn phát hiện và can thiệp vào những giai đoạn sớm của lịch sử tự nhiên. Những hoạt động phòng ngừa được xây dựng căn cứ trên khái niệm này. Hiểu một cách đơn giản, phòng ngừa có nghĩa là ngăn chặn sự phát triển của bệnh trước khi nó xuất hiện. Tuy nhiên, tùy theo cơ chế tác dụng của biện pháp được áp dụng, phòng ngừa có thể chia làm bốn mức độ khác nhau.\n\nPhòng ngừa bậc 0: ngăn không cho yếu tố nguy cơ xuất hiện (ví dụ: cấm sản xuất thuốc lá trong phòng ngừa ung thư phổi và các bệnh tim mạch).\nPhòng ngừa bậc 1: giữ cho bệnh hoàn toàn không thể xảy ra (ví dụ: chủng ngừa đối với những bệnh truyền nhiễm).\nPhòng ngừa bậc 2: phát hiện bệnh sớm khi chưa có triệu chứng, và khi điều trị sớm có thể ngăn bệnh không khởi phát (ví dụ: làm thử nghiệm phết mỏng PAP trong sàng lọc ung thư cổ tử cung).\nPhòng ngừa bậc 3: gồm những hoạt động ngăn ngừa những hậu quả xấu hơn, hoặc những biến chứng sau khi bệnh đã khởi phát (ví dụ sử dụng thuốc ức chế β� để giảm nguy cơ tử vong đối với những bệnh nhân đã hồi phục sau nhồi máu cơ tim).\n\nNhư vậy, theo cơ chế tác dụng, những mức độ phòng ngừa bậc 0, 1, 2, và 3 đã tấn công vào các giai đoạn tương ứng sau đây của lịch sử tự nhiên: trước giai đoạn cảm nhiễm, trong giai đoạn cảm nhiễm, trong giai đoạn bán lâm sàng; và trong 2 giai đoạn lâm sàng, và hồi phục, tàn phế, hoặc chết.\n\n\n2.3.2.2 Hiện tượng tảng băng trong chẩn đoán lâm sàng\n\nDo phổ lâm sàng thay đổi rộng, những trường hợp được chẩn đoán bởi bác sĩ lâm sàng trong cộng đồng thường chỉ đại diện cho \"chóp của tảng băng\". Có nhiều trường hợp còn quá sớm để chẩn đoán hoặc có thể vẫn không có triệu chứng.\n\nVí dụ, theo Tổ Chức Y Tế Thế Giới, đối với sốt xuất huyết dengue, khi có một trường hợp sốc được chẩn đoán trong bệnh viện thì tại khu vực sinh sống của trường hợp đó có khoảng 150 đến 200 người đang mắc bệnh lặng lẽ chưa được phát hiện.\n\nMột trường hợp chẩn đoán được tại bệnh viện chính là phần nổi của tảng băng thấy được, nhưng phần chìm rất lớn lại không thể thấy được. Điều thách thức đối với người làm công tác sức khoẻ công cộng là những người nhiễm trùng tiềm tàng hoặc không chẩn đoán được vẫn có thể lây cho những người khác. Những người bị nhiễm nhưng có bệnh bán lâm sàng như vậy được gọi là những người mang trùng. Người mang trùng thường là những người ở trong thời kỳ ủ bệnh hoặc nhiễm trùng tiềm ẩn. Những người bệnh sởi, viêm gan A, và một vài bệnh khác có khả năng lây vào một vài ngày trước khi khởi phát những triệu chứng. Mặt khác, những người mang trùng cũng có thể là những người đã phục hồi từ bệnh lâm sàng của họ, như những người mang vi-rút viêm gan B mạn tính."
  },
  {
    "objectID": "epibasic_02_dis_epi.html#sự-lây-truyền-bệnh",
    "href": "epibasic_02_dis_epi.html#sự-lây-truyền-bệnh",
    "title": "2  Bệnh và dịch",
    "section": "2.4 Sự lây truyền bệnh",
    "text": "2.4 Sự lây truyền bệnh\n\n2.4.1 Dây chuyền Lây\n\nBệnh được lây truyền khi tác nhân rời bỏ vật chủ, hoặc túc chủ của nó, qua một ngõ ra, rồi được chuyển tải bằng một cách thức lây nào đó, và xâm nhập qua một ngõ vào thích hợp để gây nhiễm một túc chủ cảm thụ mới. Quá trình được gọi là dây chuyền lây. Quá trình này bao gồm các thành tố chính sau:\n\n2.4.1.1 Vật chủ\nVật chủ của một tác nhân gây bệnh là nơi cư trú mà trong đó tác nhân sống và phát triển. Một vật chủ có thể là con người, súc vật, hoặc môi trường. Vật chủ không nhất thiết là nguồn mà từ đó tác nhân được chuyển qua túc chủ. Ví dụ:\n\nVật chủ của Clostridium botulinum là đất, nhưng nguồn của hầu hết những trường hợp nhiễm botulinum là thực phẩm đóng hộp không kỹ có chứa bào tử C. botulinum.\n\n\n2.4.1.1.1 Vật chủ người\nCó hai loại vật chủ người, đó là những người bệnh có triệu chứng, và những người mang trùng (người bệnh không có biểu hiện lâm sàng nhưng có khả năng truyền tác nhân sang người khác). Có nhiều loại người mang trùng khác nhau:\n\nNgười mang trùng không triệu chứng: không bao giờ có triệu chứng trong suốt thời gian bị nhiễm.\nNgười mang trùng ẩn: những người có khả năng lây truyền trước khi bệnh lâm sàng.\nNgười hồi phục mang trùng: những người có khả năng lây truyền sau khi bệnh lâm sàng.\nNgười mang trùng mạn tính: người tiếp tục mang một tác nhân (như virus viêm gan B, hoặc Salmonella typhi) trong một thời gian kéo dài (hàng tháng hoặc hàng năm) theo sau lần nhiễm trùng ban đầu.\n\nKhả năng truyền bệnh của những người mang trùng là đáng kể vì họ không nhận thức được rằng họ bị nhiễm cho nên không có biện pháp phòng ngừa đặc biệt để ngăn lây lan. Ngược lại, những người có triệu chứng thường ít có khả năng lây rộng rãi vì khi có triệu chứng, họ sẽ có nhiều khả năng được chẩn đoán và điều trị, do đó giảm thiểu cơ hội tiếp xúc với những người khác.\n\n\n2.4.1.1.2 Vật chủ súc vật\nNhững bệnh của động vật (thí dụ, bệnh lở mồm long móng ở bò, heo; bệnh than ở cừu; dịch hạch ở động vật gặm nhấm; giun lươn ở lợn; bệnh dại ở chó, mèo, v.v.) có thể lây từ súc vật sang người trong một số điều kiện. Trong những bệnh này, súc vật là vật chủ, và người là vật chủ tình cờ. Một nhóm khác của những bệnh với vật chủ súc vật là những bệnh gây ra do virus được truyền do côn trùng (thí dụ, viêm não St. Louis lây truyền do muỗi), hoặc gây ra do ký sinh trùng (thí dụ, sốt rét lây truyền do muỗi, và bệnh sán máng lây truyền do ốc nước ngọt).\n\n\n2.4.1.1.3 Vật chủ môi trường\nThực vật, đất, và nước trong môi trường cũng là những vật chủ đối với một số tác nhân lây, thí dụ, vi nấm (sống và nhân lên trong đất), trực khuẩn Legionnaire (trong những hồ chứa nước từ những tháp làm lạnh, hoặc những máy cô đặc sinh hơi tạo ra).\n\n\n\n2.4.1.2 Ngõ ra\nNgõ ra là con đường mà qua đó một tác nhân rời túc chủ nguồn. Ngõ ra thường tương ứng với điểm mà tác nhân khu trú, thí dụ, trực khuẩn lao và virus cúm rời đường hô hấp; sán máng qua nước tiểu; vi khuẩn tả trong phân, những con cái ghẻ Sarcoptes scabiei trong vết thương ở da; và virus đường ruột 70, một tác nhân của viêm kết mạc xuất huyết, trong những chất tiết của kết mạc. Một vài những tác nhân qua đường máu có thể đi ra bằng cách xuyên qua nhau (bệnh ban Đức, giang mai, bệnh nhiễm toxoplasma), trong khi những loại khác đi ra bằng đường da, cụ thể là qua vết cắt hoặc kim (viêm gan B), hoặc qua những động vật tiết túc hút máu (sốt rét).\n\n\n2.4.1.3 Những cách thức lây\nSau khi một tác nhân rời khỏi vật chủ tự nhiên của nó, nó có thể được truyền qua một túc chủ cảm thụ bằng nhiều cách. Những cách thức lây có thể được xếp loại là trực tiếp hoặc gián tiếp; hoặc ngang hoặc thẳng (Bảng 2.1).\n\n\n\nCách thức lây\n\n\n\n\n\nTrực tiếp\n- Tiếp xúc trực tiếp\n\n\n \n- Sự lan ra của giọt nước bọt\n\n\nGián tiếp\n- Qua không khí\n\n\n \n- Qua vật chuyên chở\n\n\n \n- Qua sinh vật trung gian\n\n\n \n+ Cơ học\n\n\n \n+ Sinh học\n\n\nNgang\n- Qua vật chuyên chở\n\n\n \n- Tiếp xúc trực tiếp người - người\n\n\n \n- Qua sinh vật trung gian\n\n\nThẳng\n- Mẹ truyền sang con qua nhau\n\n\n\nTrong sự lây truyền trực tiếp, tác nhân được chuyển giao tức khắc từ một vật chủ sang một túc chủ cảm thụ do tiếp xúc trực tiếp (qua hôn, tiếp xúc da-da, giao hợp, tiếp xúc với đất hoặc thực vật có chứa những sinh vật lây), hoặc qua trung gian của giọt nước bọt (trong một khoảng cách ngắn trước khi giọt nước bọt rơi xuống đất).\nTrong sự lây truyền gián tiếp, một tác nhân được chuyên chở từ một vật chủ tới một túc chủ cảm thụ bởi:\n\nNhững hạt treo trong không khí.\nNhững sinh vật trung gian (trung gian có sự sống, ví dụ, những động vật tiết túc, như ruồi chuyên chở Shigella trên những phần phụ của nó). Trong sự chuyên chở cơ học, tác nhân không nhân lên, hoặc không trải qua những biến đổi sinh lý bên trong sinh vật trung gian. Khi tác nhân trải qua những biến đổi bên trong sinh vật trung gian, thì sinh vật trung gian sẽ là một vật chuyên chở sinh học, và được xem là một túc chủ trung gian.\nNhững vật chuyên chở, là những trung gian không có sự sống, thí dụ như thức ăn, nước, những sản phẩm sinh học (máu), những đồ dùng (khăn tay, chăn màn, dao phẩu thuật, v.v.).\n\n\n\n2.4.1.4 Ngõ vào\nTác nhân gây bệnh xâm nhập vào túc chủ cảm thụ qua một ngõ vào, và ngõ vào để xâm nhập một túc chủ mới thường giống với ngõ ra để rời bỏ túc chủ nguồn. Thí dụ, virus cúm phải rời đường hô hấp của túc chủ nguồn và xâm nhập đường hô hấp của túc chủ mới. Đường lây truyền phổ biến của nhiều tác nhân gây bệnh đường ruột là đường \"phân-miệng\", vì những sinh vật được thải ra trong phân, được chuyên chở bởi những bàn tay bẩn, và rồi chuyển sang một vật chuyên chở (như thức ăn, nước, hoặc dụng cụ nấu nướng) để vào miệng của một túc chủ mới. Những ngõ vào khác gồm có da (bệnh giun móc), màng nhày (giang mai, mắt hột), và máu (viêm gan B).\n\n\n2.4.1.5 Túc chủ\nMắc xích cuối cùng trong dây chuyền lây là một túc chủ cảm thụ. Tính cảm thụ của một túc chủ tùy thuộc vào những yếu tố di truyền, tính miễn dịch thụ đắc đặc hiệu, và những yếu tố chung khác. Các yếu tố chung chống lại sự nhiễm bệnh gồm da, màng nhày, tính axít của bao tử, tiêm mao trong đường hô hấp, phản xạ ho, những đáp ứng miễn dịch không đặc hiệu có thể thay đổi khả năng của một cá nhân để kháng lại sự nhiễm hoặc hạn chế tính sinh bệnh. Những yếu tố chung có thể tăng tính cảm thụ là suy dinh dưỡng, nghiện rượu, và bệnh hoặc điều trị làm hỏng đáp ứng miễn dich không đặc hiệu.\nTính miễn dịch thụ đắc đặc hiệu có liên quan đến những kháng thể bảo vệ trực tiếp chống lại một tác nhân cụ thể. Một cá nhân có được kháng thể bảo vệ bằng hai cách:\n\nMiễn dịch chủ động: tự phát triển kháng thể qua đáp ứng với nhiễm trùng, vắc-xin, hoặc giả độc tố.\nMiễn dịch thụ động: thụ đắc những kháng thể từ mẹ trước khi sanh, qua nhau, hoặc do được tiêm kháng độc tố hoặc globulin miễn dịch.\n\nDây chuyền lây có thể bị gián đoạn khi một tác nhân không tìm được một túc chủ cảm thụ. Điều này có thể xảy ra khi trong quần thể có một tỉ lệ cao những cá thể đề kháng lại với tác nhân. Khả năng lan truyền của mầm bệnh ở nhóm người này là không cao mà tập trung vào một số ít người cảm nhiễm. Khái niệm này được gọi là tính miễn dịch quần thể.\nMức độ cần có của tính miễn dịch quần thể để ngăn chận, hoặc triệt tiêu một trận bùng phát dịch là thay đổi tùy theo bệnh. Theo lý thuyết, tính miễn dịch quần thể có nghiã là không phải người nào ở trong cộng đồng cũng phải đề kháng (miễn dịch) để ngừa sự lan truyền bệnh và sự xảy ra dịch. Thực tế đã cho thấy, tính miễn dịch quần thể đã không ngăn được những trận bùng phát bệnh sởi và ban Đức trong những dân số có mức miễn dịch cao khoảng 85 đến 90%. Một vấn đề là, trong những dân số miễn dịch cao, con số tương đối ít của những người cảm nhiễm thường quần tụ thành những nhóm nhỏ, do có những đặc tính riêng về văn hoá và kinh tế xã hội. Nếu tác nhân được đưa vào một trong những nhóm nhỏ này, một trận bùng phát dịch có thể xảy ra.\n\n\n\n2.4.2 Những ứng dụng của dây chuyền lây\nNếu biết được một tác nhân đi ra và xâm nhập một túc chủ như thế nào, và những cách lây truyền của nó là gì, chúng ta có thể xác định được những biện pháp kiểm soát thích hợp. Nói chung, những biện pháp kiểm soát nên nhắm vào mắt xích nào trong dây chuyền lây là nhạy cảm nhất với sự can thiệp.\nĐối với một số bệnh, sự can thiệp thích hợp nhất có thể hướng vào việc kiểm soát hoặc loại bỏ tác nhân ngay từ nguồn. Trong bệnh viện, những bệnh nhân có thể được điều trị hoặc/và cách ly, với những cảnh giác \"cẩn thận lây đường ruột\", \"cẩn thận lây hô hấp\", \"cẩn thận chung\", và những thứ tương tự cho những lối ra khác nhau. Trong cộng đồng, đất có thể được giải nhiễm hoặc phủ lại để ngăn sự thoát ra của tác nhân.\nĐôi khi chúng ta hướng những can thiệp vào cách thức lây. Đối với sự lây truyền trực tiếp, chúng ta có thể cho điều trị những túc chủ nguồn, hoặc giáo dục túc chủ nguồn tránh loại tiếp xúc đặc thù có liên quan đến sự lây truyền. Trong bệnh viện, vì hầu hết những sự nhiễm trùng được truyền đi qua tiếp xúc trực tiếp, rửa tay là cách quan trọng nhất để ngăn bệnh lan tràn. Đối với kiểu lây truyền qua vật chuyên chở, có thể giải nhiễm hoặc loại bỏ vật chuyên chở. Đối với kiểu lây phân-miệng, có thể giảm nguy cơ nhiễm trong tương lai bằng cách thanh khiết lại môi trường, và giáo dục người dân làm tốt vệ sinh cá nhân. Đối với kiểu lây qua không khí, có thể thay đổi sự thông khí hoặc áp suất không khí, và lọc hoặc xử lý không khí. Đối với kiểu lây qua sinh vật trung gian, chúng ta thường kiểm soát bằng cách giảm thiểu hoặc thanh toán quần thể côn trùng trung gian.\nCuối cùng, chúng ta có thể áp dụng những biện pháp bảo vệ ngõ vào của một túc chủ có khả năng cảm thụ, hoặc giảm tính cảm thụ của một túc chủ có khả năng. Thí dụ, bao tay và khẩu trang của một nha sĩ là nhằm bảo vệ nha sĩ đối với nước bọt, những chất tiết, và máu của bệnh nhân, cũng như bảo vệ bệnh nhân đối với nha sĩ. Kháng sinh phòng ngừa và tiêm chủng là những chiến lược để cải thiện sự bảo vệ của một túc chủ cảm thụ."
  },
  {
    "objectID": "epibasic_02_dis_epi.html#sự-xuất-hiện-dịch",
    "href": "epibasic_02_dis_epi.html#sự-xuất-hiện-dịch",
    "title": "2  Bệnh và dịch",
    "section": "2.5 Sự xuất hiện dịch",
    "text": "2.5 Sự xuất hiện dịch\n\n2.5.1 Mức độ hiện diện của bệnh\nCon số những trường hợp bệnh hiện diện thường xuyên trong cộng đồng là mức nền của một bệnh. Mức này không nhất thiết phải là mức mong đợi, mà trong thực tế phải bằng không. Đúng ra nó là mức quan sát được. Về mặt lý thuyết, nếu không có sự can thiệp nào xảy ra, và nếu mức độ là đủ thấp để không làm giảm tổng số người cảm thụ, bệnh sẽ tiếp tục xuất hiện mãi mãi ở mức nền. Do đó, mức nền thường được coi là mức mong đợi của bệnh. Thí dụ, trong 4 năm qua, con số những trường hợp bại liệt báo cáo là từ 5 đến 9. Do đó, giả sử rằng không có thay đổi trong dân số, chúng ta sẽ hy vọng thấy vào khoảng 7 trường hợp được báo cáo trong năm tới.\nNhững bệnh khác nhau, trong những cộng đồng khác nhau, sẽ có những mô hình khác nhau của sự xuất hiện mong đợi:\n\nmột sự xuất hiện có mô hình bất thường, với những trường hợp lẻ tẻ xảy ra vào những khoảng thời gian bất thường được gọi là ca lẻ tẻ\nmột mức độ xuất hiện duy trì ở một mức bệnh thấp cho tới trung bình được xem là mức lưu hành\nmột sự xuất hiện duy trì ở mức độ cao được gọi là mức lưu hành cao\nthỉnh thoảng, mức bệnh vượt hơn mức mong đợi, trong một vùng vào một thời điểm cụ thể, nó được gọi là một vụ dịch. Những nhân viên sức khoẻ cộng đồng thường dùng từ bùng phát, cùng một nghiã với dịch, nhưng từ bùng phát ít làm kinh động công chúng\nkhi một trận dịch lan ra một vài quốc gia hoặc đại lục, ảnh hưởng một số lớn người, nó được gọi là đại dịch.\n\nMột trận dịch có thể xảy ra khi tác nhân và túc chủ cảm thụ hiện diện đủ số, và tác nhân có thể được chuyển tải một cách có hiệu quả từ nguồn đến những túc chủ cảm thụ. Cụ thể hơn, một trận dịch có thể sinh ra trong những điều kiện sau đây:\n\nmột sự gia tăng tức thời về số lượng hoặc độc lực của tác nhân\ntác nhân vừa được đưa vào một vùng mà từ trước giờ nó không có\ncách thức lây mạnh hơn, do đó, nhiều túc chủ cảm thụ bị tiếp xúc hơn\nmột vài thay đổi về tính cảm thụ trong đáp ứng của túc chủ với tác nhân\nnhững yếu tố làm tăng sự tiếp xúc của túc chủ, hoặc gây sự xâm nhập qua những ngõ vào mới\n\n\n\n2.5.2 Các mô hình dịch\nĐôi khi chúng ta xếp loại những vụ dịch tuỳ theo chúng lan tràn như thế nào trong dân số:\n\nMột trận dịch nguồn chung là một trận dịch mà trong đó tất cả các trường hợp bệnh đều tiếp xúc với một tác nhân chung. Nếu tiếp xúc trong một khoảng thời gian tương đối ngắn, mỗi trường hợp đều phát bệnh vào cuối một thời kỳ ủ bệnh, thì trận dịch nguồn chung lại được xếp loại là một trận dịch nguồn điểm. Trận dịch của những trường hợp bệnh bạch cầu sau vụ nổ bom nguyên tử ở Hiroshima có một nguồn điểm tiếp xúc. Trong một vài trận dịch nguồn chung, những trường hợp có thể được tiếp xúc trong một khoảng thời gian nhiều ngày, nhiều tuần, hoặc lâu hơn, với sự tiếp xúc liên tục hoặc không liên tục.\nMột trận dịch không có một nguồn chung, nhưng lan dần từ người này qua người khác, được gọi là một trận dịch nhân rộng (dịch tản phát). Thường thì sự lây truyền là do tiếp xúc trực tiếp người-người, như với bệnh giang mai. Sự lây truyền có thể sinh ra do vật chuyên chở, như sự lây truyền viêm gan B hoặc HIV do dùng chung kim chích, hoặc sinh ra do sinh vật trung gian, như sự lây truyền của sốt vàng do muỗi.\nMột số trận dịch có thể có những đặc tính của cả dịch nguồn chung và dịch nhân rộng. Mô hình của một trận dịch nguồn chung theo sau bởi một sự lan truyền thứ phát người-người không phải là hiếm. Những kiểu này được gọi là dịch hỗn hợp. Thí dụ, trong một trận dịch nguồn chung của lỵ trực trùng xảy ra ở một nhóm 3.000 phụ nữ tham gia một nhạc hội, nhiều người phát sinh triệu chứng sau khi trở về nhà. Trong một vài tuần sau, người ta phát hiện những trường hợp lỵ lan tràn theo kiểu lây người-người từ những người tham dự nhạc hội.\nCuối cùng, một số trận dịch không là nguồn chung theo nghiã thông thường, cũng không là nhân rộng kiểu người-người. Những trận dịch bệnh truyền từ động vật và bệnh truyền do sinh vật trung gian xuất hiện có thể là do tỉ suất nhiễm toàn bộ đầy đủ của những loài túc chủ, sự hiện diện đủ của những sinh vật trung gian, và có đủ tương tác người-sinh vật trung gian. Những thí dụ gồm có bệnh Lyme ảnh hưởng một vài tiểu bang đông bắc Hoa kỳ vào cuối những năm 1980, và trận dịch lớn bệnh viêm não St. Louis ở Florida năm 1990."
  },
  {
    "objectID": "idana_25_surv_mapping.html",
    "href": "idana_25_surv_mapping.html",
    "title": "51  Spatial Mapping of Infectious Disease Risk",
    "section": "",
    "text": "Source: Ewan Cameron. Chapter 26."
  },
  {
    "objectID": "idana_25_surv_mapping.html#why-need-high-resolution-infectious-disease-risk-maps",
    "href": "idana_25_surv_mapping.html#why-need-high-resolution-infectious-disease-risk-maps",
    "title": "51  Spatial Mapping of Infectious Disease Risk",
    "section": "51.1 Why need High-Resolution, Infectious Disease Risk Maps?",
    "text": "51.1 Why need High-Resolution, Infectious Disease Risk Maps?\nAvailability of data (electronic health information system, spatial data, imaging, GIS) –> possible to produce risk maps\nThese risk maps are valuable for stakeholders:\n\nnational disease control program: allocate resources, identify intervention target\nsupra-national organizations (WHO etc): evaluation of progress (???)\nindividual: travel plan, performance of health system\n\nProducing these maps require formal statistical approach because:\n\nInfectious disease data features: disaggregation, interrogation (???)\nstochasticity of the generating process"
  },
  {
    "objectID": "idana_25_surv_mapping.html#how-to-produce-high-resolution-infectious-disease-risk-maps",
    "href": "idana_25_surv_mapping.html#how-to-produce-high-resolution-infectious-disease-risk-maps",
    "title": "51  Spatial Mapping of Infectious Disease Risk",
    "section": "51.2 How to produce High-Resolution, Infectious Disease Risk Maps?",
    "text": "51.2 How to produce High-Resolution, Infectious Disease Risk Maps?\n\n51.2.1 What are required data?\n\n51.2.1.1 Georeferenced disease data\n\n\n51.2.1.2 Spatial covariates"
  },
  {
    "objectID": "idana_25_surv_mapping.html#what-are-challenges-to-use-and-improve-disease-risk-maps",
    "href": "idana_25_surv_mapping.html#what-are-challenges-to-use-and-improve-disease-risk-maps",
    "title": "51  Spatial Mapping of Infectious Disease Risk",
    "section": "51.3 What are challenges to use and improve disease risk maps?",
    "text": "51.3 What are challenges to use and improve disease risk maps?"
  }
]